{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Project_Notebook_Christopher.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcK4xEzRs9xK"
      },
      "source": [
        "---\n",
        "## Note from the Teachers:\n",
        "We added a header with information about your project. \n",
        "This is useful since we want to keep a database of all the cool projects participants have made during the courses.\n",
        "We will save the code in our database and host on github a page to show all the projects. Therefore it is more practical to add some information in the header of each notebook.\n",
        "Thanks a lot for the understanding and for taking care of it.\n",
        "\n",
        "You can delete this cell if you want\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgD3XbPds9xQ"
      },
      "source": [
        "# Project Name (replace with your project name)\n",
        "Project description (replace with your project description, you can use the same from the `INFO.md` file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v27TWYp_s9xR"
      },
      "source": [
        "### Project Repo \n",
        "link (replace if you have your own repo, otherwise delete)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Nbtlpq0s9xS"
      },
      "source": [
        "## Participants:\n",
        "Please list here all the participants alongside with any information you may want to be visible. This will be hosted on a opencampus.sh repository, so if you want to keep a connection to your github user include this information here. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OAz0ANbs9xS"
      },
      "source": [
        "### Course and Semester\n",
        "Add here in which course and in which semester it was done."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0JN1ztBs9xT"
      },
      "source": [
        "### License\n",
        "If you are releasing the software under some certain license, you can mention it and also include the `LICENSE.md` file in the folder\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKuWTTVMs9xU"
      },
      "source": [
        "# Here you can start your code! Thanks"
      ],
      "execution_count": 713,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mui49FlG0VA3"
      },
      "source": [
        "pip install -q tf-models-official\n"
      ],
      "execution_count": 714,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yio7mvFl0jSZ"
      },
      "source": [
        "#!pip install bert-tensorflow"
      ],
      "execution_count": 715,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9U9Scx8Q1jps",
        "outputId": "4fe460fe-b7d9-46f9-acd1-aedb1b030ed8"
      },
      "source": [
        "!pip install tensorflow-text"
      ],
      "execution_count": 716,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-text in /usr/local/lib/python3.7/dist-packages (2.5.0)\n",
            "Requirement already satisfied: tensorflow<2.6,>=2.5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text) (2.5.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text) (0.12.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text) (1.12)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text) (1.1.2)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text) (1.19.5)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text) (2.5.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text) (1.6.3)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text) (0.4.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text) (1.1.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text) (0.36.2)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text) (3.7.4.3)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text) (3.1.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text) (0.2.0)\n",
            "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text) (1.12.1)\n",
            "Requirement already satisfied: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text) (1.34.1)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text) (2.5.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text) (0.12.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text) (1.15.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text) (1.8.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text) (57.0.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text) (0.4.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text) (0.6.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text) (1.31.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text) (3.3.4)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow<2.6,>=2.5.0->tensorflow-text) (1.5.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text) (1.3.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text) (2021.5.30)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text) (0.2.8)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text) (4.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text) (3.1.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text) (3.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGobds8gs9xV"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import pyplot\n",
        "import seaborn as sns\n",
        "import csv\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import regularizers\n",
        "from keras import regularizers\n",
        "import tensorflow.keras.utils as ku\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import recall_score, precision_score, f1_score\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "#import tensorflow_text as text\n",
        "from official.nlp import optimization  # to create AdamW optimizer\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "\n",
        "import nltk \n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.tokenize import word_tokenize \n",
        "\n",
        "import tensorflow as tf\n",
        "import random\n",
        "\n",
        "import tensorflow_text as text \n",
        "\n",
        "from official.modeling import tf_utils\n",
        "from official import nlp\n",
        "from official.nlp import bert\n",
        "\n",
        "# Load the required submodules\n",
        "import official.nlp.optimization\n",
        "import official.nlp.bert.bert_models\n",
        "import official.nlp.bert.configs\n",
        "import official.nlp.bert.run_classifier\n",
        "import official.nlp.bert.tokenization\n",
        "import official.nlp.data.classifier_data_lib\n",
        "import official.nlp.modeling.losses\n",
        "import official.nlp.modeling.models\n",
        "import official.nlp.modeling.networks"
      ],
      "execution_count": 717,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vR3fbbyfs9xV"
      },
      "source": [
        "#In case of Google Colab run this:\n",
        "#from google.colab import files\n",
        "#uploaded = files.upload()"
      ],
      "execution_count": 718,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tqN0yUK8O5E"
      },
      "source": [
        "import pandas as pd\n",
        "url = 'https://nc.rootnix.de/s/KS7Hkn8Cw4mdCMm/download/data_MailsAndPC_UPDATE.csv'\n",
        "azubi_df = pd.read_csv(url,index_col=0,parse_dates=[0])"
      ],
      "execution_count": 719,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qU6uzHys9xW"
      },
      "source": [
        "#import io\n",
        "#azubi_df = pd.read_csv(io.BytesIO(uploaded['data_MailsAndPC.csv']))"
      ],
      "execution_count": 720,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFzncW_Ouehq"
      },
      "source": [
        "#Global Hyperparameters\n",
        "vocab_size = 3000\n",
        "embedding_dim = 32\n",
        "max_length = 120\n",
        "trunc_type='post'\n",
        "padding_type='post'\n",
        "oov_tok = \"<OOV>\"\n",
        "\n"
      ],
      "execution_count": 721,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NHHGH37vnVz"
      },
      "source": [
        "executionType = 1"
      ],
      "execution_count": 722,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HM2nxJkJs9xW"
      },
      "source": [
        "#In case of local github export run this:\n",
        "#DATA_FOLDER = './../data'\n",
        "#AZUBI_DATA = 'data_MailsAndPC.csv'\n",
        "#AZUBI_DATA_CLEANED = 'data_MailsAndPC_cleaned.csv'\n",
        "#azubi_df = pd.read_csv(os.path.join(DATA_FOLDER, AZUBI_DATA))"
      ],
      "execution_count": 723,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfeGAqr4s9xX"
      },
      "source": [
        ""
      ],
      "execution_count": 723,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lm2kVe3jz61A"
      },
      "source": [
        "# Data Preparation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCvEwcJz-daw"
      },
      "source": [
        "## Data Preparation Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Zm-nnaJQqWN"
      },
      "source": [
        "def selectColumns(azubi_df, mail, item):\n",
        "\n",
        "  azubi_df_selected_columns = azubi_df[[mail,item]]\n",
        "\n",
        "  return azubi_df_selected_columns"
      ],
      "execution_count": 724,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "253GubJ5s9xZ"
      },
      "source": [
        "def cleanupDataframe(azubi_df, mail, item):\n",
        "    #Remove unneccesary columns\n",
        "    #azubi_df = azubi_df.drop(columns=['Unnamed: 0', 'id'])\n",
        "    #Remove \"cr\". Assumption made, that there are no real words containing cr in the mails.\n",
        "    azubi_df[\"S1_mail\"] = azubi_df[\"S1_mail\"].str.replace(\"cr\", \" \")\n",
        "    azubi_df[\"S2_mail\"] = azubi_df[\"S2_mail\"].str.replace(\"cr\", \" \")\n",
        "    azubi_df[\"S3_mail\"] = azubi_df[\"S3_mail\"].str.replace(\"cr\", \" \")\n",
        "    \n",
        "    azubi_df = selectColumns(azubi_df, mail, item)\n",
        "    #Drop NA rows to only have full datasets\n",
        "    azubi_df = azubi_df.dropna()\n",
        "    #Select all rows without '99' | ~ inverts the operator\n",
        "    dropThisNumber = 99\n",
        "    azubi_df = azubi_df[~azubi_df.eq(dropThisNumber).any(1)]\n",
        "    #Select all rows without '6' | ~ inverts the operator\n",
        "    #dropThisNumber = 6\n",
        "    #azubi_df = azubi_df[~azubi_df.eq(dropThisNumber).any(1)]\n",
        "    #Reset the index of the Dataframe\n",
        "    azubi_df = azubi_df.reset_index(drop=True)\n",
        "    return azubi_df"
      ],
      "execution_count": 725,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNwHseQc2pCV"
      },
      "source": [
        "def trainDevTestSplit_sklearn(X, Y, testSize, randomSeed, stratify):\n",
        "  #Splits by test size into Train / Dev\n",
        "  #Splits dev then 50/50 into dev and Test\n",
        "\n",
        "  if (stratify == True):\n",
        "    xTrain, xDev, yTrain, yDev = train_test_split(X, Y, test_size=testSize,stratify = Y, random_state=randomSeed)\n",
        "  else:\n",
        "    xTrain, xDev, yTrain, yDev = train_test_split(X, Y, test_size=testSize, random_state=randomSeed)\n",
        "\n",
        "  xTest = xDev[:len(xDev)//2]\n",
        "  yTest = yDev[:len(yDev)//2]\n",
        "  \n",
        "  xDev = xDev[len(xDev)//2:]\n",
        "  yDev = yDev[len(yDev)//2:]\n",
        "  #xDev, yDev, xTest, yTest = train_test_split(xDev, yDev, test_size =0.5, random_state = randomSeed)\n",
        "\n",
        "  return xTrain, yTrain, xDev, yDev, xTest, yTest"
      ],
      "execution_count": 726,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLjrs8Ql3ZsB"
      },
      "source": [
        "def tokenizeData(vocab_size, oov_tok, train_sentences, max_length, padding_type, trunc_type):\n",
        "    tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
        "    tokenizer.fit_on_texts(train_sentences)\n",
        "   \n",
        "    word_index = tokenizer.word_index\n",
        "    vocab_size=len(word_index)\n",
        "\n",
        "    print(\"Word Index: \\n\")\n",
        "    print(word_index)\n",
        "    \n",
        "    sequences = tokenizer.texts_to_sequences(train_sentences)\n",
        "\n",
        "    print(\"Sequences: \\n\")\n",
        "    print(sequences)\n",
        "    padded = pad_sequences(sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "    return padded"
      ],
      "execution_count": 727,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_XrQiWFyR3D"
      },
      "source": [
        "def oneHotEncodePreSplit(yTrain, removeZeros):\n",
        "  #a = np.array([1, 0, 3])\n",
        "  #yTrain = yTrain.astype(int)\n",
        "  \n",
        "  print(\"Unique Values:\")\n",
        "  print(np.unique(yTrain))\n",
        "  print(\"\\n\")\n",
        "  yTrainOneHot = tf.keras.utils.to_categorical(yTrain)\n",
        "  print(\"Classes before removing zeros:\")\n",
        "  print(yTrainOneHot)\n",
        "  print(yTrainOneHot.sum(axis=0))\n",
        "  print(\"\\n\")\n",
        "\n",
        "  if (removeZeros == True):\n",
        "    yTrainOneHot = yTrainOneHot[:,~np.all(yTrainOneHot == 0, axis = 0)]\n",
        "  print(\"Classes after removing zeros:\")\n",
        "  print(yTrainOneHot)\n",
        "  print(yTrainOneHot.sum(axis=0))\n",
        "  print(\"\\n\")\n",
        "\n",
        "  return yTrainOneHot"
      ],
      "execution_count": 728,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXudDjuNRXo1"
      },
      "source": [
        "def makeListSelectedColumns(azubi_df, mail, score):\n",
        "  #Sentence S1\n",
        "  mailSentences = azubi_df[mail].tolist()\n",
        "  #Labels S1\n",
        "  scoreLabels = azubi_df[score].tolist()\n",
        "\n",
        "  return mailSentences, scoreLabels"
      ],
      "execution_count": 729,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkFz6t2qQUOn"
      },
      "source": [
        "## Stop Words\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMlPtbzIUoTH"
      },
      "source": [
        "#stopwords\n",
        "def removeStopWordsSelectedColumns(azubi_df_cleaned, mail):\n",
        "\n",
        "  nltk.download('punkt')\n",
        "  nltk.download('stopwords')\n",
        "\n",
        "  stemmer = SnowballStemmer(\"german\")\n",
        "  stop_words = set(stopwords.words(\"german\"))\n",
        "  #stop_words.add('Meier')\n",
        "  #stop_words.add('Neumann')\n",
        "\n",
        "  azubi_df_cleaned_no_stopwords = pd.DataFrame()\n",
        "\n",
        "  pat = r'\\b(?:{})\\b'.format('|'.join(stop_words))\n",
        "  azubi_df_cleaned[mail] = azubi_df_cleaned[mail].str.replace(pat, '')\n",
        "  azubi_df_cleaned[mail] = azubi_df_cleaned[mail].str.replace(r'\\s+', ' ')\n",
        "\n",
        "  return azubi_df_cleaned\n",
        "\n",
        "#allerdings Wörter wie \"nicht\" enthalten"
      ],
      "execution_count": 730,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqY5lr_m28HI"
      },
      "source": [
        "## Show Model Performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5nwd0d726iw"
      },
      "source": [
        "def showModelPerformance(history, string):\n",
        "    plt.plot(history.history[string])\n",
        "    plt.plot(history.history['val_'+string])\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(string)\n",
        "    plt.title('Random Forest Model')\n",
        "    plt.legend([string, 'val_'+string])\n",
        "    plt.show()\n",
        "\n",
        "    return"
      ],
      "execution_count": 731,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wT2uSeoc2JfL"
      },
      "source": [
        "## Execute Data Preparation\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1o5IhvFEhdq"
      },
      "source": [
        "## Combine all mails for a4s2_combined_i2b score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fY2PLulBOQ6"
      },
      "source": [
        "#Create new dataframe\n",
        "azubi_df_mails_and_scored_combined = pd.DataFrame(columns=[\"Mails_Combined\", \"a4s_combined_i2b\"])\n",
        "#Use cleanup function to select the correct data from the dataframe\n",
        "azubi_df_mail1 = cleanupDataframe(azubi_df, 'S1_mail', 'a4s1i2b')\n",
        "azubi_df_mail2 = cleanupDataframe(azubi_df, 'S2_mail', 'a4s2i2b')\n",
        "azubi_df_mail3 = cleanupDataframe(azubi_df, 'S3_mail', 'a4s3i2b')"
      ],
      "execution_count": 732,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_3-vjNKCJTk"
      },
      "source": [
        "#Rename the columns\n",
        "azubi_df_mail1_renamed = azubi_df_mail1.rename(columns={\"S1_mail\": \"Mails_Combined\", \"a4s1i2b\": \"a4s_combined_i2b\"})\n",
        "azubi_df_mail2_renamed = azubi_df_mail2.rename(columns={\"S2_mail\": \"Mails_Combined\", \"a4s2i2b\": \"a4s_combined_i2b\"})\n",
        "azubi_df_mail3_renamed = azubi_df_mail3.rename(columns={\"S3_mail\": \"Mails_Combined\", \"a4s3i2b\": \"a4s_combined_i2b\"})"
      ],
      "execution_count": 733,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hdbd12mCv0f"
      },
      "source": [
        "#Append the renamed columns, ignore index so it is appended at the end\n",
        "azubi_df_mails_and_scored_combined = azubi_df_mails_and_scored_combined.append(azubi_df_mail1_renamed, ignore_index=True)\n",
        "azubi_df_mails_and_scored_combined = azubi_df_mails_and_scored_combined.append(azubi_df_mail2_renamed, ignore_index=True)\n",
        "azubi_df_mails_and_scored_combined = azubi_df_mails_and_scored_combined.append(azubi_df_mail3_renamed, ignore_index=True)"
      ],
      "execution_count": 734,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78LqLIZjC5zb"
      },
      "source": [
        "azubi_df_mails_and_scored_combined = azubi_df_mails_and_scored_combined[azubi_df_mails_and_scored_combined.a4s_combined_i2b != 9.0]\n",
        "azubi_df_mails_and_scored_combined = azubi_df_mails_and_scored_combined[azubi_df_mails_and_scored_combined.a4s_combined_i2b != 2.0]\n",
        "azubi_df_mails_and_scored_combined = azubi_df_mails_and_scored_combined.reset_index()"
      ],
      "execution_count": 735,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAjvQ3lw3vif",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "6be153ac-eb34-49e0-aa8e-bb6a0167ea8e"
      },
      "source": [
        "azubi_df_mails_and_scored_combined['Mails_Combined'][2]"
      ],
      "execution_count": 736,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'bitte kommen Sie rüber und erklären mir es selbst'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 736
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaoTEgisESHp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4aa6e86b-6db3-4030-9694-eb889f1d5131"
      },
      "source": [
        "azubi_df_mails_and_scored_combined['a4s_combined_i2b']"
      ],
      "execution_count": 737,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       1.0\n",
              "1       1.0\n",
              "2       0.0\n",
              "3       1.0\n",
              "4       1.0\n",
              "       ... \n",
              "2082    0.0\n",
              "2083    1.0\n",
              "2084    1.0\n",
              "2085    1.0\n",
              "2086    1.0\n",
              "Name: a4s_combined_i2b, Length: 2087, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 737
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BltN2QS78Tdc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "1d5f0832-83b4-46c6-bb7a-2c7b70039c9e"
      },
      "source": [
        "azubi_df_mails_and_scored_combined"
      ],
      "execution_count": 738,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>Mails_Combined</th>\n",
              "      <th>a4s_combined_i2b</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Hallo Fr. Meier,  leider konnte ich die von Ih...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Ihre Antwort...   Der EP Plan weicht viel zuse...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>bitte kommen Sie rüber und erklären mir es selbst</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Sehr geehrte Frau Meier,  leider konnte Ich Ih...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Hallo Frau Meier,  das Controlling hat für das...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2082</th>\n",
              "      <td>2135</td>\n",
              "      <td>Hallo Herr Neumann,  gerne würde ich Ihnen mei...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2083</th>\n",
              "      <td>2136</td>\n",
              "      <td>Hallo Herr Neumann,  leider konnte ich aus der...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2084</th>\n",
              "      <td>2137</td>\n",
              "      <td>Ihre Antwort...  Guten Tag Herr Neumann,  leid...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2085</th>\n",
              "      <td>2138</td>\n",
              "      <td>Guten Tag Herr Neumann,  hier die beiden Liste...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2086</th>\n",
              "      <td>2139</td>\n",
              "      <td>Hallo Herr Neumann,  anbei die ausfüllten Tabe...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2087 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      index  ... a4s_combined_i2b\n",
              "0         0  ...              1.0\n",
              "1         1  ...              1.0\n",
              "2         2  ...              0.0\n",
              "3         3  ...              1.0\n",
              "4         5  ...              1.0\n",
              "...     ...  ...              ...\n",
              "2082   2135  ...              0.0\n",
              "2083   2136  ...              1.0\n",
              "2084   2137  ...              1.0\n",
              "2085   2138  ...              1.0\n",
              "2086   2139  ...              1.0\n",
              "\n",
              "[2087 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 738
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XW2NGDIXg9Zh"
      },
      "source": [
        "### Selected Columns Scores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvdbiU3MRJH-"
      },
      "source": [
        "def prepareDataSelectedColumns(azubi_df, mail, score, doCleanup, paddedOutput, word2vec): \n",
        "  #Prepare the data\n",
        "  if doCleanup == True:\n",
        "    azubi_df_cleaned = cleanupDataframe(azubi_df, mail, score)\n",
        "  else:\n",
        "    azubi_df_cleaned = azubi_df\n",
        "  #print(azubi_df_cleaned[score][9])\n",
        "\n",
        "  #Remove Stop words\n",
        "  #azubi_df_cleaned_no_stopwords = removeStopWordsSelectedColumns(azubi_df_cleaned, mail)\n",
        "  mailSentences, scoreLabels = makeListSelectedColumns(azubi_df_cleaned, mail, score)\n",
        "  print(len(mailSentences))\n",
        "  print(len(scoreLabels))\n",
        "\n",
        "  yTrainOneHot = oneHotEncodePreSplit(np.array(scoreLabels), True)\n",
        "\n",
        "  if paddedOutput == True and word2vec == False:\n",
        "    print(\"Padded Output True\")\n",
        "    padded = tokenizeData(vocab_size, oov_tok, mailSentences, max_length, padding_type, trunc_type)\n",
        "    xTrain, yTrain, xVal, yVal, xTest, yTest = trainDevTestSplit_sklearn(padded, yTrainOneHot, 0.1, 42, False)\n",
        "  elif word2vec == True and paddedOutput == False:\n",
        "    padded = word2vecTokenizer(mailSentences, glove_vectors)\n",
        "    print(padded)\n",
        "  else:\n",
        "    xTrain, yTrain, xVal, yVal, xTest, yTest = trainDevTestSplit_sklearn(mailSentences, yTrainOneHot, 0.4, 42, False)\n",
        "\n",
        "  xTrainArray = xTrain#np.array(xTrain)\n",
        "  yTrainArray = yTrain#np.array(yTrain)\n",
        "\n",
        "\n",
        "  xValArray = xVal#np.array(xVal)\n",
        "  yValArray = yVal#np.array(yVal)\n",
        "\n",
        "\n",
        "  xTestArray = xTest#np.array(xTest)\n",
        "  yTestArray = yTest#np.array(yTest)\n",
        "  print(len(xTrainArray))\n",
        "  print(len(yTrainArray))\n",
        "  print(len(xValArray))\n",
        "  print(len(yValArray))\n",
        "  print(len(xTestArray))\n",
        "  print(len(yTestArray))\n",
        "\n",
        "\n",
        "  return xTrainArray, yTrainArray, xValArray, yValArray, xTestArray, yTestArray, azubi_df_cleaned\n"
      ],
      "execution_count": 739,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cwbmv5MJ79OJ"
      },
      "source": [
        "#xTrainArray"
      ],
      "execution_count": 740,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AB1YDw5ZS83B",
        "outputId": "55c8b582-3150-4074-855e-9ef633230d3d"
      },
      "source": [
        "xTrainArray, yTrainArray, xValArray, yValArray, xTestArray, yTestArray, azubi_df_cleaned_no_stopwords = prepareDataSelectedColumns(azubi_df_mails_and_scored_combined, 'Mails_Combined', 'a4s_combined_i2b', False, False, False)"
      ],
      "execution_count": 741,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2087\n",
            "2087\n",
            "Unique Values:\n",
            "[0. 1.]\n",
            "\n",
            "\n",
            "Classes before removing zeros:\n",
            "[[0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " ...\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]]\n",
            "[ 146. 1941.]\n",
            "\n",
            "\n",
            "Classes after removing zeros:\n",
            "[[0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " ...\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]]\n",
            "[ 146. 1941.]\n",
            "\n",
            "\n",
            "1252\n",
            "1252\n",
            "418\n",
            "418\n",
            "417\n",
            "417\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrP4YZ4mw2bp",
        "outputId": "11b2df46-43d5-4385-d3fc-7bffb7d07e73"
      },
      "source": [
        "xTrainArray2, yTrainArray2, xValArray2, yValArray2, xTestArray2, yTestArray2, azubi_df_cleaned_no_stopwords2 = prepareDataSelectedColumns(azubi_df, 'S2_mail', 'a4s2i2b', True,  False, False)"
      ],
      "execution_count": 742,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "725\n",
            "725\n",
            "Unique Values:\n",
            "[0. 1. 2. 9.]\n",
            "\n",
            "\n",
            "Classes before removing zeros:\n",
            "[[1. 0. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]]\n",
            "[ 38. 666.   1.   0.   0.   0.   0.   0.   0.  20.]\n",
            "\n",
            "\n",
            "Classes after removing zeros:\n",
            "[[1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " ...\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]]\n",
            "[ 38. 666.   1.  20.]\n",
            "\n",
            "\n",
            "435\n",
            "435\n",
            "145\n",
            "145\n",
            "145\n",
            "145\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-G6cvVenIvA"
      },
      "source": [
        "#only for a4s2i2b\n",
        "#yTrainArray = np.delete(yTrainArray, 2, 1)\n",
        "#yTrainArray = np.delete(yTrainArray, 2, 1)\n",
        "\n",
        "#yValArray = np.delete(yValArray, 2, 1)\n",
        "#yValArray = np.delete(yValArray, 2, 1)\n",
        "\n",
        "#yTestArray = np.delete(yTestArray, 2, 1)\n",
        "#yTestArray = np.delete(yTestArray, 2, 1)"
      ],
      "execution_count": 743,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIuVyHM6dswP",
        "outputId": "759c6160-3b48-4bf7-9652-fee4339879a7"
      },
      "source": [
        "yTrainArray.sum(axis=0)"
      ],
      "execution_count": 744,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  87., 1165.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 744
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJlA2Rm1d4Gt",
        "outputId": "c2d4242e-2969-4edc-b454-0a3c188a156c"
      },
      "source": [
        "yValArray.sum(axis=0)"
      ],
      "execution_count": 745,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 33., 385.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 745
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHNKE5odd4cC",
        "outputId": "db1c7cc1-952b-4d18-e305-ed8ee7c97f70"
      },
      "source": [
        "yTestArray.sum(axis=0)"
      ],
      "execution_count": 746,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 26., 391.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 746
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CfS1_yCgi9U",
        "outputId": "0b34b04c-ed7a-4377-d99c-4b0b7014fc36"
      },
      "source": [
        "pd.set_option('display.max_rows', azubi_df.shape[0]+1)\n",
        "azubi_df['a4s1i2b'].unique()"
      ],
      "execution_count": 747,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1.,  0.,  9., nan])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 747
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zc-W0br9St45"
      },
      "source": [
        "### Sum Scores Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwSqeUqH2MFL"
      },
      "source": [
        "def prepareDataSumScores(azubi_df, mail, score, paddedOutput): \n",
        "  #Prepare the data\n",
        "  azubi_df_cleaned = cleanupDataframe(azubi_df)\n",
        "  print(azubi_df_cleaned['S1_mail'][5])\n",
        "\n",
        "  #Remove Stop words\n",
        "  azubi_df_cleaned_no_stopwords = removeStopWords(azubi_df_cleaned)\n",
        "\n",
        "  azubi_df_list , s1MailSentences, s1MailA3Labels, s1MailA4Labels, s2MailSentences, s2MailA3Labels, s2MailA4Labels, s3MailSentences, s3MailA3Labels, s3MailA4Labels = makeList(azubi_df_cleaned_no_stopwords)\n",
        "\n",
        "  if (mail == 'S1'):\n",
        "    if (score == 'A3'):\n",
        "      yTrainOneHot,yTrainOneHotNoZeros = oneHotEncodePreSplit(np.array(s1MailA3Labels), False)\n",
        "    elif (score == 'A4'):\n",
        "      yTrainOneHot,yTrainOneHotNoZeros = oneHotEncodePreSplit(np.array(s1MailA4Labels), False)\n",
        "    \n",
        "    if (paddedOutput == True):\n",
        "      padded = tokenizeData(vocab_size, oov_tok, s1MailSentences, max_length, padding_type, trunc_type)\n",
        "      xTrain, yTrain, xVal, yVal, xTest, yTest = trainDevTestSplit_sklearn(padded, yTrainOneHot, 0.1, 42, False)\n",
        "    elif (paddedOutput == False):\n",
        "      xTrain, yTrain, xVal, yVal, xTest, yTest = trainDevTestSplit_sklearn(s1MailSentences, yTrainOneHot, 0.4, 42, False)\n",
        "  elif (mail == 'S2'):\n",
        "    if (score == 'A3'):\n",
        "      yTrainOneHot,yTrainOneHotNoZeros = oneHotEncodePreSplit(np.array(s2MailA3Labels), False)\n",
        "    elif (score == 'A4'):\n",
        "      yTrainOneHot,yTrainOneHotNoZeros = oneHotEncodePreSplit(np.array(s2MailA4Labels), False)\n",
        "    \n",
        "    if (paddedOutput == True):\n",
        "      padded = tokenizeData(vocab_size, oov_tok, s2MailSentences, max_length, padding_type, trunc_type)\n",
        "      xTrain, yTrain, xVal, yVal, xTest, yTest = trainDevTestSplit_sklearn(padded, yTrainOneHot, 0.1, 42, False)\n",
        "    elif (paddedOutput == False):\n",
        "      xTrain, yTrain, xVal, yVal, xTest, yTest = trainDevTestSplit_sklearn(s2MailSentences, yTrainOneHot, 0.4, 42, False)\n",
        "    \n",
        "  elif (mail == 'S3'):\n",
        "    if (score == 'A3'):\n",
        "      yTrainOneHot,yTrainOneHotNoZeros = oneHotEncodePreSplit(np.array(s3MailA3Labels), False)\n",
        "    elif (score == 'A4'):\n",
        "      yTrainOneHot,yTrainOneHotNoZeros = oneHotEncodePreSplit(np.array(s3MailA4Labels), False)\n",
        "\n",
        "    if (paddedOutput == True):\n",
        "      padded = tokenizeData(vocab_size, oov_tok, s3MailSentences, max_length, padding_type, trunc_type)\n",
        "      xTrain, yTrain, xVal, yVal, xTest, yTest = trainDevTestSplit_sklearn(padded, yTrainOneHot, 0.1, 42, False)\n",
        "    elif (paddedOutput == False):\n",
        "      xTrain, yTrain, xVal, yVal, xTest, yTest = trainDevTestSplit_sklearn(s3MailSentences, yTrainOneHot, 0.4, 42, False)\n",
        "\n",
        "  else:\n",
        "    print('Select S1, S2 or S3 as mail and A3 or A4 as score')\n",
        "\n",
        "    \n",
        "  \n",
        "\n",
        "\n",
        "  #train_padded = tokenizeData(vocab_size, oov_tok, xTrain, max_length, padding_type, trunc_type)\n",
        "  #validation_padded = tokenizeData_val(xVal, max_length, padding_type)\n",
        "  #test_padded = tokenizeData_val(xTest, max_length, padding_type)\n",
        "\n",
        "  train_padded = np.array(xTrain)\n",
        "  yTrain = np.array(yTrain)\n",
        "  #yTrainOneHot = yTrain\n",
        "  #yTrain = np.reshape(yTrain, (yTrain.shape[0], 1))\n",
        "\n",
        "  validation_padded = np.array(xVal)\n",
        "  yVal = np.array(yVal)\n",
        "  #yValOneHot = yVal\n",
        "  #yVal = np.reshape(yVal, (yVal.shape[0], 1))\n",
        "\n",
        "  test_padded = np.array(xTest)\n",
        "  yTest = np.array(yTest)\n",
        "  #yTestOneHot = yTest\n",
        "\n",
        "  return train_padded, validation_padded, test_padded, yTrain, yVal, yTest\n",
        "\n",
        "  #yTest = np.reshape(yTest, (yTest.shape[0], 1))\n",
        "\n",
        "  #yTrainOneHot, yValOneHot, yTestOneHot, yTrainOneHotNoZeros, yValOneHotNoZeros, yTestOneHotNoZeros = oneHotEncodeAlternative(yTrain, yVal, yTest, False)"
      ],
      "execution_count": 748,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMwsseDWjNQz"
      },
      "source": [
        "#train_padded_sum, validation_padded_sum, test_padded_sum, yTrain_padded_sum, yVal_padded_sum, yTest_padded_sum = prepareDataSumScores(azubi_df, 'S1', 'A4', True)"
      ],
      "execution_count": 749,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zI2IakehAEoo"
      },
      "source": [
        "#train_sum, validation_sum, test_sum, yTrain_sum, yVal_sum, yTest_sum = prepareDataSumScores(azubi_df, 'S1', 'A4', False)"
      ],
      "execution_count": 750,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUs3UIAtjF40"
      },
      "source": [
        "### Currently not needed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WV0p4MkcFrC5"
      },
      "source": [
        "if (executionType == 2):    \n",
        "  #Prepare the data\n",
        "  azubi_df_cleaned = cleanupDataframeGetSingleClass(azubi_df, 0, 'a3s1')\n",
        "\n",
        "  #Remove Stop words\n",
        "  azubi_df_cleaned_no_stopwords = removeStopWords(azubi_df_cleaned)\n",
        "\n",
        "  azubi_df_list , s1MailSentences, s1MailA3Labels, s1MailA4Labels, s2MailSentences, s2MailA3Labels, s2MailA4Labels, s3MailSentences, s3MailA3Labels, s3MailA4Labels = makeList(azubi_df_cleaned_no_stopwords)\n",
        "  xTrain, yTrain, xVal, yVal, xTest, yTest = trainDevTestSplit_sklearn(s1MailSentences, s1MailA3Labels, 0.4, 42, True)\n",
        "\n",
        "  train_padded = tokenizeData(vocab_size, oov_tok, xTrain, max_length, padding_type, trunc_type)\n",
        "  validation_padded = tokenizeData_val(xVal, max_length, padding_type)\n",
        "  test_padded = tokenizeData_val(xTest, max_length, padding_type)\n",
        "\n",
        "  train_padded = np.array(train_padded)\n",
        "  yTrain = np.array(yTrain)\n",
        "  yTrain = np.reshape(yTrain, (yTrain.shape[0], 1))\n",
        "\n",
        "  validation_padded = np.array(validation_padded)\n",
        "  yVal = np.array(yVal)\n",
        "  yVal = np.reshape(yVal, (yVal.shape[0], 1))\n",
        "\n",
        "  test_padded = np.array(test_padded)\n",
        "  yTest = np.array(yTest)\n",
        "  yTest = np.reshape(yTest, (yTest.shape[0], 1))\n",
        "\n",
        "  yTrainOneHot,yValOneHot,yTestOneHot = oneHotEncode(yTrain, yVal, yTest, True)"
      ],
      "execution_count": 751,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKXx615VjItY"
      },
      "source": [
        "### Single scores data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZy46pqjndUS"
      },
      "source": [
        "def prepareDataSingleScores(azubi_df, mail, score):\n",
        "  #Prepare the data\n",
        "  azubi_df_cleaned = cleanupDataframe(azubi_df)\n",
        "\n",
        "  #Remove Stop words\n",
        "  azubi_df_cleaned_no_stopwords = removeStopWords(azubi_df_cleaned)\n",
        "\n",
        "  azubi_df_list , s1MailSentences, s1Maila3s1i1a, s1Maila3s1i1b, s1Maila3s1i2a, s1Maila3s1i2b, s1Maila3s1i2c = makeListSubscores(azubi_df_cleaned_no_stopwords)\n",
        "  xTrain, yTrain, xVal, yVal, xTest, yTest = trainDevTestSplit_sklearn(s1MailSentences, s1Maila3s1i1a, 0.4, 42, False)\n",
        "\n",
        "  if (mail == 'S1'):\n",
        "    if (score == 'a3s1i1a'):\n",
        "      yTrainOneHot,yTrainOneHotNoZeros = oneHotEncodePreSplit(np.array(s1Maila3s1i1a), True)\n",
        "    elif (score == 'a3s1i1b'):\n",
        "      yTrainOneHot,yTrainOneHotNoZeros = oneHotEncodePreSplit(np.array(s1Maila3s1i1b), True)\n",
        "    elif (score == 'a3s1i2a'):\n",
        "      yTrainOneHot,yTrainOneHotNoZeros = oneHotEncodePreSplit(np.array(s1Maila3s1i2a), True)\n",
        "    elif (score == 'a3s1i2b'):\n",
        "      yTrainOneHot,yTrainOneHotNoZeros = oneHotEncodePreSplit(np.array(s1Maila3s1i2b), True)\n",
        "    elif (score == 'a3s1i2c'):\n",
        "      yTrainOneHot,yTrainOneHotNoZeros = oneHotEncodePreSplit(np.array(s1Maila3s1i2c), True)\n",
        "  \n",
        "    xTrain, yTrain, xVal, yVal, xTest, yTest = trainDevTestSplit_sklearn(s1MailSentences, yTrainOneHotNoZeros, 0.4, 42, False)\n",
        "\n",
        "  train_padded = tokenizeData(vocab_size, oov_tok, xTrain, max_length, padding_type, trunc_type)\n",
        "  validation_padded = tokenizeData_val(xVal, max_length, padding_type)\n",
        "  test_padded = tokenizeData_val(xTest, max_length, padding_type)\n",
        "\n",
        "  train_padded = np.array(train_padded)\n",
        "  yTrain = np.array(yTrain)\n",
        "  #yTrain = np.reshape(yTrain, (yTrain.shape[0], 1))\n",
        "\n",
        "  validation_padded = np.array(validation_padded)\n",
        "  yVal = np.array(yVal)\n",
        "  #yVal = np.reshape(yVal, (yVal.shape[0], 1))\n",
        "\n",
        "  test_padded = np.array(test_padded)\n",
        "  yTest = np.array(yTest)\n",
        "  #yTest = np.reshape(yTest, (yTest.shape[0], 1))\n",
        "\n",
        "  #yTrainOneHot, yValOneHot, yTestOneHot, yTrainOneHotNoZeros, yValOneHotNoZeros, yTestOneHotNoZeros = oneHotEncodeAlternative(yTrain, yVal, yTest)\n",
        "\n",
        "  return train_padded, validation_padded, test_padded, yTrain, yVal, yTest, xTrain, yTrain, xVal"
      ],
      "execution_count": 752,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGE2DHkdseCj"
      },
      "source": [
        "#train_padded_single, validation_padded_single, test_padded_single, yTrain_single, yVal_single, yTest_single, xTrain_single, yTrain_single, xVal_single = prepareDataSingleScores(azubi_df, 'S1', 'a3s1i1b')"
      ],
      "execution_count": 753,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhviE7NGmq45"
      },
      "source": [
        ""
      ],
      "execution_count": 753,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWc73CUEbB3O"
      },
      "source": [
        "# Transfer Learning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhQ_iEeMDQdH"
      },
      "source": [
        "# preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRxc1PdRvJCZ"
      },
      "source": [
        "Sources i used to create and understand word2vec:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_Xk8HYm8viJ"
      },
      "source": [
        "#Word2vec approach. We followed a mix out of several turoials:\n",
        "#    https://radimrehurek.com/gensim/auto_examples/tutorials/run_word2vec.html\n",
        "#    https://discuss.huggingface.co/t/generate-raw-word-embeddings-using-transformer-models-like-bert-for-downstream-process/2958\n",
        "#    https://towardsdatascience.com/text-classification-with-nlp-tf-idf-vs-word2vec-vs-bert-41ff868d1794\n",
        "#    https://phdstatsphys.wordpress.com/2018/12/27/word2vec-how-to-train-and-update-it/"
      ],
      "execution_count": 754,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBWZEgbwvbPT"
      },
      "source": [
        "Import, especially gensin and gensim.downloader for word2vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lz9tCOQo9CCk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a199508-aab0-49f9-a6b1-e8c484a80f29"
      },
      "source": [
        "## for data\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "## for plotting\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "## for processing\n",
        "import re\n",
        "import nltk\n",
        "## for bag-of-words\n",
        "from sklearn import feature_extraction, model_selection, naive_bayes, pipeline, manifold, preprocessing\n",
        "## for explainer\n",
        "!pip install lime\n",
        "from lime import lime_text\n",
        "## for word embedding\n",
        "import gensim\n",
        "import gensim.downloader as gensim_api\n",
        "## for deep learning\n",
        "from tensorflow.keras import models, layers, preprocessing as kprocessing\n",
        "from tensorflow.keras import backend as K\n",
        "## for bert language model\n",
        "#!pip install transformer\n",
        "#from transformer"
      ],
      "execution_count": 755,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lime in /usr/local/lib/python3.7/dist-packages (0.2.0.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from lime) (1.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from lime) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from lime) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from lime) (0.22.2.post1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from lime) (4.41.1)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.7/dist-packages (from lime) (0.16.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime) (2.4.7)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->lime) (1.0.1)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (7.1.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (2.4.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (1.1.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (2.5.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->lime) (1.15.0)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image>=0.12->lime) (4.4.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDR33jzfvipv"
      },
      "source": [
        "As always, take a look at the data first to ensure everything is all right"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iABfsxDK9SvI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "61da5446-f0c4-423c-aca1-8ddf76fad6b9"
      },
      "source": [
        "azubi_df_mails_and_scored_combined.sample(10)"
      ],
      "execution_count": 756,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>Mails_Combined</th>\n",
              "      <th>a4s_combined_i2b</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1270</th>\n",
              "      <td>1312</td>\n",
              "      <td>Hallo Herr Neumann,  im Anhang finden Sie die ...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>65</td>\n",
              "      <td>Hallo Frau Meier,  leider konnte ich die Aufga...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>937</th>\n",
              "      <td>967</td>\n",
              "      <td>Sehr geehrter Herr Neumann,  nach Analyse der ...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1142</th>\n",
              "      <td>1182</td>\n",
              "      <td>Hallo Herr Neumann,   anbei eine unter Zetdruc...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>931</th>\n",
              "      <td>960</td>\n",
              "      <td>Hallo Herr Neumann,  anbei der Angebotsverglei...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>782</th>\n",
              "      <td>806</td>\n",
              "      <td>Hallo Herr Neumann,  ich habe mich über die ve...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2073</th>\n",
              "      <td>2126</td>\n",
              "      <td>Guten Tag Herr Neumann,  anbei habe ich Ihnen ...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1298</th>\n",
              "      <td>1340</td>\n",
              "      <td>Hallo Herr Neumann,  leider gibt es nicht so v...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1039</th>\n",
              "      <td>1075</td>\n",
              "      <td>Hallo Herr Neumann,  ich würde mich für den de...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>692</th>\n",
              "      <td>715</td>\n",
              "      <td>Guten Tag Frau Meier,  da die mir gestellte Au...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      index  ... a4s_combined_i2b\n",
              "1270   1312  ...              1.0\n",
              "64       65  ...              1.0\n",
              "937     967  ...              1.0\n",
              "1142   1182  ...              1.0\n",
              "931     960  ...              1.0\n",
              "782     806  ...              1.0\n",
              "2073   2126  ...              1.0\n",
              "1298   1340  ...              1.0\n",
              "1039   1075  ...              1.0\n",
              "692     715  ...              1.0\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 756
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2NdVFnuvnbA"
      },
      "source": [
        "And we also want to make sure our data set is balanced. Which is not the case. Thus, we include weights later in the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BevGZsl-9WXD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "29f73bba-aa88-4305-d6d7-b65347b58a6a"
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "fig.suptitle(\"count\", fontsize=12)\n",
        "azubi_df_mails_and_scored_combined[\"a4s_combined_i2b\"].reset_index().groupby(\"a4s_combined_i2b\").count().sort_values(by= \n",
        "       \"index\").plot(kind=\"barh\", legend=False, \n",
        "        ax=ax).grid(axis='x')\n",
        "plt.show()"
      ],
      "execution_count": 757,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeI5OUUJv0Lk"
      },
      "source": [
        "And we split the data into train and test set. A validation set will be splitted seperately."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACP3DkQh9ay6"
      },
      "source": [
        "## split dataset\n",
        "dtf_train, dtf_test = model_selection.train_test_split(azubi_df_cleaned_no_stopwords, test_size=0.3)## get target\n",
        "y_train = dtf_train[\"a4s_combined_i2b\"].values\n",
        "y_test = dtf_test[\"a4s_combined_i2b\"].values"
      ],
      "execution_count": 758,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8PPmugt9-Ux"
      },
      "source": [
        "# word2vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v87T-zvAv3f7"
      },
      "source": [
        "Here we start with word2vec and this might take some time so here are some facts about word2vec: \n",
        "\n",
        "The word2vec tool takes a text corpus as input and produces the word vectors as output. It first constructs a vocabulary from the training text data and then learns vector representation of words. The resulting word vector file can be used as features in many natural language processing and machine learning applications.\n",
        "\n",
        "(more info: https://code.google.com/archive/p/word2vec/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrteU-xt-Cbm"
      },
      "source": [
        "# download word2vec takes 10 min\n",
        "#we could use this word2vec pretrained model by using this line of code, but instead we wanted to make a word2vec embedding with our own corpus, because word2vec wasn't trained with business mails\n",
        "# nlp = gensim_api.load(\"word2vec-google-news-300\") "
      ],
      "execution_count": 759,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9vQrKNOwPqx"
      },
      "source": [
        "Lets use word2vec with our corpus. We define unigrams here to determine polite word sequences. The functions we use are part of gensim, so this is rather easy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4J7iw1d8-HHF"
      },
      "source": [
        "corpus =  dtf_train[\"Mails_Combined\"]\n",
        "## create list of lists of unigrams (#Sehr)\n",
        "lst_corpus = []\n",
        "for string in corpus:\n",
        "   lst_words = string.split()\n",
        "   lst_grams = [\" \".join(lst_words[i:i+1]) \n",
        "               for i in range(0, len(lst_words), 1)]\n",
        "   lst_corpus.append(lst_grams)\n",
        "## detect bigrams (#Sehr geehrter) and trigrams (#Sehr geehrte:r Herr:Frau)\n",
        "bigrams_detector = gensim.models.phrases.Phrases(lst_corpus, \n",
        "                 delimiter=\" \".encode(), min_count=5, threshold=10)\n",
        "bigrams_detector = gensim.models.phrases.Phraser(bigrams_detector)\n",
        "trigrams_detector = gensim.models.phrases.Phrases(bigrams_detector[lst_corpus], \n",
        "            delimiter=\" \".encode(), min_count=5, threshold=10)\n",
        "trigrams_detector = gensim.models.phrases.Phraser(trigrams_detector)\n",
        "\n"
      ],
      "execution_count": 760,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2HC1uJbwgpT"
      },
      "source": [
        "This is crucial now. We determine the setup to create polite word embedding vectors.\n",
        "- target size = of the word vectors\n",
        "- window = is the maximum distance between the current and predicted word within a mail\n",
        "- sg = training algorithm we  use skip-grams (sg=1) as it was used in the tutorial and this should also in general lead to the best results in most cases\n",
        "- iter = number of iterations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DeKTzAh-XU5"
      },
      "source": [
        "#word2vec setup\n",
        "#play with size=300, window = 8? mean lenght?\n",
        "# target size, mean length window of distance, and sgram 1: has proven robust \n",
        "nlp = gensim.models.word2vec.Word2Vec(lst_corpus, size=64,   \n",
        "            window=3, min_count=1, sg=1, iter=30)\n",
        "\n"
      ],
      "execution_count": 761,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGC_PGASzfqb"
      },
      "source": [
        "How is our word embedding shaped? It is a 1 dimensional 50 array. Lets take a closer look:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvgZ7UMH-oGC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11d625c1-baed-4072-dcf6-de5709261517"
      },
      "source": [
        "word = \"freundlichen\"\n",
        "nlp[word].shape"
      ],
      "execution_count": 762,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(64,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 762
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zle-LzZCzpAA"
      },
      "source": [
        "And this is actually the vector space. Cool Hmm? Test it for yourself if you like to play with..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rR5dB8iRzL6O",
        "outputId": "95f8dcbd-fd31-4740-d02b-b1c18b39d991"
      },
      "source": [
        "nlp[word]"
      ],
      "execution_count": 763,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.6553515 , -1.1455084 ,  0.8517343 , -1.2689476 ,  0.41236147,\n",
              "       -0.03748571, -0.31895998,  0.00964641,  0.21146026, -0.7259291 ,\n",
              "        0.90726954, -0.06552348,  1.2589552 ,  0.5860698 , -0.82214934,\n",
              "        0.21177629, -0.45627105,  0.8936007 ,  0.29338866, -0.14219056,\n",
              "       -0.89757186, -0.4464977 ,  1.2040031 , -0.9772042 , -0.22573052,\n",
              "       -0.2630451 , -0.7658094 , -0.783389  , -0.44716915, -0.9545822 ,\n",
              "        0.32767314,  0.29711518,  0.09008924,  1.5261972 ,  0.8991424 ,\n",
              "       -1.3111138 , -0.3508462 , -0.14892447,  0.5782781 , -1.4533671 ,\n",
              "       -0.39172578, -1.4945995 ,  0.9149613 ,  0.6064246 ,  0.6206169 ,\n",
              "       -0.6447094 , -1.2880694 , -0.7531845 , -0.8334579 ,  0.35481176,\n",
              "       -0.34968364,  0.6457623 , -1.5059001 , -0.9594395 , -1.290033  ,\n",
              "       -0.35372642, -1.9534377 , -0.26501137, -0.09096038, -0.19022202,\n",
              "        0.94751143,  0.5071983 ,  0.3709728 , -0.8841195 ], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 763
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HtQcl3qzwcD"
      },
      "source": [
        "We can even print this in in 3d space with related words..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "id": "YRevGKcn00KO",
        "outputId": "c82152d7-5575-487f-f911-0316b0568a84"
      },
      "source": [
        "word = word\n",
        "fig = plt.figure()## word embedding\n",
        "tot_words = [word] + [tupla[0] for tupla in \n",
        "                 nlp.most_similar(word, topn=20)]\n",
        "X = nlp[tot_words]## pca to reduce dimensionality from 300 to 3\n",
        "pca = manifold.TSNE(perplexity=40, n_components=3, init='pca')\n",
        "X = pca.fit_transform(X)## create dtf\n",
        "dtf_ = pd.DataFrame(X, index=tot_words, columns=[\"x\",\"y\",\"z\"])\n",
        "dtf_[\"input\"] = 0\n",
        "dtf_[\"input\"].iloc[0:1] = 1## plot 3d\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.scatter(dtf_[dtf_[\"input\"]==0]['x'], \n",
        "           dtf_[dtf_[\"input\"]==0]['y'], \n",
        "           dtf_[dtf_[\"input\"]==0]['z'], c=\"black\")\n",
        "ax.scatter(dtf_[dtf_[\"input\"]==1]['x'], \n",
        "           dtf_[dtf_[\"input\"]==1]['y'], \n",
        "           dtf_[dtf_[\"input\"]==1]['z'], c=\"red\")\n",
        "ax.set(xlabel=None, ylabel=None, zlabel=None, xticklabels=[], \n",
        "       yticklabels=[], zticklabels=[])\n",
        "for label, row in dtf_[[\"x\",\"y\",\"z\"]].iterrows():\n",
        "    x, y, z = row\n",
        "    ax.text(x, y, z, s=label)"
      ],
      "execution_count": 764,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  iloc._setitem_with_indexer(indexer, value)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qn3wMYrp-u5r"
      },
      "source": [
        "note: maybe we can add here a download buttom to upload these files in this cool tensorflow showcase for word embeddings\n",
        "shortcoming: need to be lowercased, thus might not be appropriate to measure politeness in german, e.g. Sie vs. sie / Ihre vs ihre"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBaTS7m91h-8"
      },
      "source": [
        "Ok, lets use our created embeddings by transforming this corpus to the Word2Vec into a list of sequences using tensorflow/keras and pad.sequences.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixp_Jlmn-6_P"
      },
      "source": [
        "## tokenize text\n",
        "tokenizer = kprocessing.text.Tokenizer(lower=True, split=' ', \n",
        "                     oov_token=\"NaN\", \n",
        "                     filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n')\n",
        "tokenizer.fit_on_texts(lst_corpus)\n",
        "dic_vocabulary = tokenizer.word_index\n",
        "\n",
        "## create sequence\n",
        "lst_text2seq= tokenizer.texts_to_sequences(lst_corpus)\n",
        "\n",
        "## padding sequence\n",
        "X_train = kprocessing.sequence.pad_sequences(lst_text2seq, \n",
        "                    maxlen=150, padding=\"post\", truncating=\"post\") #need to think about maxlen"
      ],
      "execution_count": 765,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iH87Hb31_nX"
      },
      "source": [
        "How does our features look like? We see here a feature map where we see that some mails contains more features (black) than others."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIIO2aPi-9nY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "367db53a-c928-411b-d464-604a883cbefd"
      },
      "source": [
        "sns.heatmap(X_train==0, vmin=0, vmax=1, cbar=False)\n",
        "plt.show()\n",
        "#feature matrixy visual x * 120"
      ],
      "execution_count": 766,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mgp0iiC228Az"
      },
      "source": [
        "this is optional and it throws errors when it comes to the dict, due to missing words in the dict... maybe caused by lowercased words?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tG5mpsFK_Ast",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73272ea9-278d-496a-9a51-35d658108174"
      },
      "source": [
        "i = 10\n",
        "\n",
        "# list of text: [\"I like this\", ...]\n",
        "len_txt = len(dtf_train[\"Mails_Combined\"].iloc[i].split())\n",
        "print(\"from: \", dtf_train[\"Mails_Combined\"].iloc[i], \"| len:\", len_txt)\n",
        "\n",
        "# sequence of token ids: [[1, 2, 3], ...]\n",
        "len_tokens = len(X_train[i])\n",
        "print(\"to: \", X_train[i], \"| len:\", len(X_train[i]))\n",
        "\n",
        "# vocabulary: {\"I\":1, \"like\":2, \"this\":3, ...}\n",
        "print(\"check: \", dtf_train[\"Mails_Combined\"].iloc[i].split()[0], \n",
        "      \" -- idx in vocabulary -->\", )\n",
        "      #dic_vocabulary[dtf_train[\"Mails_Combined\"].iloc[i].split()[0]]) # <---- this is the error\n",
        "\n",
        "print(\"vocabulary: \", dict(list(dic_vocabulary.items())[0:10]), \"... (padding element, 0)\")"
      ],
      "execution_count": 767,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "from:  Ihre Antwort...Hallo Frau Meier,  das war ein Satz mit x..., das war wohl nix!!! | len: 14\n",
            "to:  [ 107 1254   32   38   25  114   45 4486    6 4487   25  114  662 4488\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0] | len: 150\n",
            "check:  Ihre  -- idx in vocabulary -->\n",
            "vocabulary:  {'NaN': 1, 'ich': 2, 'die': 3, 'der': 4, 'und': 5, 'mit': 6, 'zu': 7, 'nicht': 8, 'wir': 9, 'in': 10} ... (padding element, 0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9V4DZcK4574"
      },
      "source": [
        "We then \"engineer\" the same features on the test set too!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6b_H1Lh_FOY"
      },
      "source": [
        "### do some engineering\n",
        "corpus = dtf_test[\"Mails_Combined\"]\n",
        "## create list of n-grams\n",
        "lst_corpus = []\n",
        "for string in corpus:\n",
        "    lst_words = string.split()\n",
        "    lst_grams = [\" \".join(lst_words[i:i+1]) for i in range(0, \n",
        "                 len(lst_words), 1)]\n",
        "    lst_corpus.append(lst_grams)\n",
        "    ## detect common bigrams and trigrams using the fitted detectors\n",
        "lst_corpus = list(bigrams_detector[lst_corpus])\n",
        "lst_corpus = list(trigrams_detector[lst_corpus])\n",
        "## text to sequence with the fitted tokenizer\n",
        "lst_text2seq = tokenizer.texts_to_sequences(lst_corpus)\n",
        "## padding sequence\n",
        "X_test = kprocessing.sequence.pad_sequences(lst_text2seq, maxlen=120,\n",
        "             padding=\"post\", truncating=\"post\")"
      ],
      "execution_count": 768,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxSJvtn25XvA"
      },
      "source": [
        "And now we create the matrix of embeddings that will be used as a weight matrix in the neural network classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lj7yHfD_Hvx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a364d042-de8b-441c-ea8c-411b0ac8dcd5"
      },
      "source": [
        "## start the matrix (length of vocabulary x vector size) with all 0s\n",
        "embeddings = np.zeros((len(dic_vocabulary)+1, 300))\n",
        "\n",
        "for word,idx in dic_vocabulary.items():\n",
        "    ## update the row with vector\n",
        "    try:\n",
        "        embeddings[idx] =  nlp[word]\n",
        "    ## if word not in model then skip and the row stays all 0s\n",
        "    except:\n",
        "        pass"
      ],
      "execution_count": 769,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  import sys\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RX-n5b3W5u75"
      },
      "source": [
        "just a final check to see if everything is all right"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N336OJ9B_K0K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64423ee4-8656-4560-ca64-d7c9858336f7"
      },
      "source": [
        "word = \"freundlichen\"\n",
        "print(\"dic[word]:\", dic_vocabulary[word], \"|idx\")\n",
        "print(\"embeddings[idx]:\", embeddings[dic_vocabulary[word]].shape, \n",
        "      \"|vector\")"
      ],
      "execution_count": 770,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dic[word]: 21 |idx\n",
            "embeddings[idx]: (300,) |vector\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUuehNOG55UJ"
      },
      "source": [
        "And here we define our model with an embedding layer. We use an embedding layer to include our embeddings as wights, and a small RNN with two 2 LSTM layers a dense layer and an output layer with 2 neurons, and a softmax as activation function. (we use this model design, as it was sucessfully used in a similar task)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2pkOoLX_O-R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f0fcdaa-776b-4f7d-b96b-031f57389bbf"
      },
      "source": [
        "x_in = layers.Input(shape=(150,))## embedding #need to adjust (shape 15 seems to be incorrect)\n",
        "\n",
        "\n",
        "\n",
        "x = layers.Embedding(input_dim=embeddings.shape[0],  \n",
        "                     output_dim=embeddings.shape[1], \n",
        "                     weights=[embeddings],\n",
        "                     input_length=15, trainable=False)(x_in)## apply attention\n",
        "#x = attention_layer(x, neurons=15)## 2 layers of bidirectional lstm\n",
        "x = layers.LSTM(units=15, dropout=0.2, \n",
        "                         return_sequences=True)(x)                                                #layers.Bidirectional(\n",
        "x = layers.LSTM(units=15, dropout=0.2)(x)## final dense layers                                    #layers.Bidirectional(\n",
        "x = layers.Dense(64, activation='relu')(x)\n",
        "y_out = layers.Dense(2, activation='softmax')(x)## compile\n",
        "\n",
        "model = models.Model(x_in, y_out)\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 771,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_14\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_15 (InputLayer)        [(None, 150)]             0         \n",
            "_________________________________________________________________\n",
            "embedding_14 (Embedding)     (None, 150, 300)          3367500   \n",
            "_________________________________________________________________\n",
            "lstm_28 (LSTM)               (None, 150, 15)           18960     \n",
            "_________________________________________________________________\n",
            "lstm_29 (LSTM)               (None, 15)                1860      \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 64)                1024      \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 3,389,474\n",
            "Trainable params: 21,974\n",
            "Non-trainable params: 3,367,500\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYrBu14c5_zB"
      },
      "source": [
        "Lets measure the inbanlance to get an idea for some class_weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiQM9hi4Imw5",
        "outputId": "1edcf191-eff7-4b2f-e156-b8cbd9036391",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# we need to fix our inbalanced dataset by using a balance function by sklearn\n",
        "from sklearn.utils import class_weight\n",
        "class_weights = class_weight.compute_class_weight('balanced',\n",
        "                                                 np.unique(y_train),\n",
        "                                                 y_train)\n",
        "class_weights"
      ],
      "execution_count": 772,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7.15686275, 0.53755523])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 772
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tgt2sVYW_S_W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "498c1e8b-d19d-4e95-df7f-15655f472a09"
      },
      "source": [
        "## encode y\n",
        "dic_y_mapping = {n:label for n,label in \n",
        "                 enumerate(np.unique(y_train))}\n",
        "inverse_dic = {v:k for k,v in dic_y_mapping.items()}\n",
        "y_train = np.array([inverse_dic[y] for y in y_train])\n",
        "\n",
        "## train\n",
        "training = model.fit(x=X_train, y=y_train, batch_size=256, \n",
        "                     epochs=50, shuffle=True, verbose=1, \n",
        "                     validation_split=0.3, class_weight={0:15, 1:1})\n",
        "\n",
        "## plot loss and accuracy\n",
        "metrics = [k for k in training.history.keys() if (\"loss\" not in k) and (\"val\" not in k)]\n",
        "fig, ax = plt.subplots(nrows=1, ncols=2, sharey=True)\n",
        "\n",
        "ax[0].set(title=\"Training\")\n",
        "ax11 = ax[0].twinx()\n",
        "ax[0].plot(training.history['loss'], color='black')\n",
        "ax[0].set_xlabel('Epochs')\n",
        "ax[0].set_ylabel('Loss', color='black')\n",
        "for metric in metrics:\n",
        "    ax11.plot(training.history[metric], label=metric)\n",
        "ax11.set_ylabel(\"Score\", color='steelblue')\n",
        "ax11.legend()\n",
        "ax[1].set(title=\"Validation\")\n",
        "ax22 = ax[1].twinx()\n",
        "\n",
        "ax[1].plot(training.history['val_loss'], color='black')\n",
        "ax[1].set_xlabel('Epochs')\n",
        "ax[1].set_ylabel('Loss', color='black')\n",
        "for metric in metrics:\n",
        "     ax22.plot(training.history['val_'+metric], label=metric)\n",
        "ax22.set_ylabel(\"Score\", color=\"steelblue\")\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 773,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "4/4 [==============================] - 5s 397ms/step - loss: 1.3584 - accuracy: 0.0686 - val_loss: 0.6954 - val_accuracy: 0.0729\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 0s 117ms/step - loss: 1.3583 - accuracy: 0.0686 - val_loss: 0.6967 - val_accuracy: 0.0729\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 0s 115ms/step - loss: 1.3580 - accuracy: 0.0686 - val_loss: 0.6978 - val_accuracy: 0.0729\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 0s 116ms/step - loss: 1.3579 - accuracy: 0.0686 - val_loss: 0.6989 - val_accuracy: 0.0729\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 0s 115ms/step - loss: 1.3578 - accuracy: 0.0686 - val_loss: 0.7001 - val_accuracy: 0.0729\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 0s 114ms/step - loss: 1.3578 - accuracy: 0.0686 - val_loss: 0.7016 - val_accuracy: 0.0729\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 0s 116ms/step - loss: 1.3576 - accuracy: 0.0686 - val_loss: 0.7027 - val_accuracy: 0.0729\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 0s 115ms/step - loss: 1.3574 - accuracy: 0.0686 - val_loss: 0.7035 - val_accuracy: 0.0729\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 0s 115ms/step - loss: 1.3574 - accuracy: 0.0686 - val_loss: 0.7047 - val_accuracy: 0.0729\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 0s 117ms/step - loss: 1.3573 - accuracy: 0.0686 - val_loss: 0.7058 - val_accuracy: 0.0729\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 0s 120ms/step - loss: 1.3572 - accuracy: 0.0686 - val_loss: 0.7070 - val_accuracy: 0.0729\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 0s 115ms/step - loss: 1.3571 - accuracy: 0.0686 - val_loss: 0.7081 - val_accuracy: 0.0729\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 0s 118ms/step - loss: 1.3570 - accuracy: 0.0686 - val_loss: 0.7092 - val_accuracy: 0.0729\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 0s 114ms/step - loss: 1.3569 - accuracy: 0.0686 - val_loss: 0.7101 - val_accuracy: 0.0729\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 0s 115ms/step - loss: 1.3570 - accuracy: 0.0686 - val_loss: 0.7114 - val_accuracy: 0.0729\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 0s 114ms/step - loss: 1.3568 - accuracy: 0.0686 - val_loss: 0.7124 - val_accuracy: 0.0729\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 0s 118ms/step - loss: 1.3568 - accuracy: 0.0686 - val_loss: 0.7135 - val_accuracy: 0.0729\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 0s 116ms/step - loss: 1.3567 - accuracy: 0.0686 - val_loss: 0.7142 - val_accuracy: 0.0729\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 0s 116ms/step - loss: 1.3567 - accuracy: 0.0686 - val_loss: 0.7151 - val_accuracy: 0.0729\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 0s 114ms/step - loss: 1.3566 - accuracy: 0.0686 - val_loss: 0.7158 - val_accuracy: 0.0729\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 0s 115ms/step - loss: 1.3566 - accuracy: 0.0686 - val_loss: 0.7163 - val_accuracy: 0.0729\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 0s 114ms/step - loss: 1.3566 - accuracy: 0.0686 - val_loss: 0.7175 - val_accuracy: 0.0729\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 0s 116ms/step - loss: 1.3565 - accuracy: 0.0686 - val_loss: 0.7181 - val_accuracy: 0.0729\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 0s 116ms/step - loss: 1.3565 - accuracy: 0.0686 - val_loss: 0.7185 - val_accuracy: 0.0729\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 0s 119ms/step - loss: 1.3564 - accuracy: 0.0686 - val_loss: 0.7192 - val_accuracy: 0.0729\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 0s 114ms/step - loss: 1.3564 - accuracy: 0.0686 - val_loss: 0.7203 - val_accuracy: 0.0729\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 0s 117ms/step - loss: 1.3564 - accuracy: 0.0686 - val_loss: 0.7212 - val_accuracy: 0.0729\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 0s 116ms/step - loss: 1.3564 - accuracy: 0.0686 - val_loss: 0.7220 - val_accuracy: 0.0729\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 0s 118ms/step - loss: 1.3563 - accuracy: 0.0686 - val_loss: 0.7227 - val_accuracy: 0.0729\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 0s 117ms/step - loss: 1.3563 - accuracy: 0.0686 - val_loss: 0.7230 - val_accuracy: 0.0729\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 0s 115ms/step - loss: 1.3563 - accuracy: 0.0686 - val_loss: 0.7235 - val_accuracy: 0.0729\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 0s 117ms/step - loss: 1.3563 - accuracy: 0.0686 - val_loss: 0.7242 - val_accuracy: 0.0729\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 0s 115ms/step - loss: 1.3562 - accuracy: 0.0686 - val_loss: 0.7245 - val_accuracy: 0.0729\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 0s 118ms/step - loss: 1.3562 - accuracy: 0.0686 - val_loss: 0.7250 - val_accuracy: 0.0729\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 0s 115ms/step - loss: 1.3562 - accuracy: 0.0686 - val_loss: 0.7256 - val_accuracy: 0.0729\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 0s 115ms/step - loss: 1.3562 - accuracy: 0.0686 - val_loss: 0.7259 - val_accuracy: 0.0729\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 0s 114ms/step - loss: 1.3562 - accuracy: 0.0686 - val_loss: 0.7263 - val_accuracy: 0.0729\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 0s 115ms/step - loss: 1.3562 - accuracy: 0.0686 - val_loss: 0.7271 - val_accuracy: 0.0729\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 0s 116ms/step - loss: 1.3562 - accuracy: 0.0686 - val_loss: 0.7276 - val_accuracy: 0.0729\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 0s 115ms/step - loss: 1.3562 - accuracy: 0.0686 - val_loss: 0.7277 - val_accuracy: 0.0729\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 0s 119ms/step - loss: 1.3562 - accuracy: 0.0686 - val_loss: 0.7282 - val_accuracy: 0.0729\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 0s 119ms/step - loss: 1.3561 - accuracy: 0.0686 - val_loss: 0.7283 - val_accuracy: 0.0729\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 0s 115ms/step - loss: 1.3562 - accuracy: 0.0686 - val_loss: 0.7290 - val_accuracy: 0.0729\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 0s 116ms/step - loss: 1.3562 - accuracy: 0.0686 - val_loss: 0.7294 - val_accuracy: 0.0729\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 0s 116ms/step - loss: 1.3561 - accuracy: 0.0686 - val_loss: 0.7294 - val_accuracy: 0.0729\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 0s 116ms/step - loss: 1.3562 - accuracy: 0.0686 - val_loss: 0.7299 - val_accuracy: 0.0729\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 0s 115ms/step - loss: 1.3561 - accuracy: 0.0686 - val_loss: 0.7302 - val_accuracy: 0.0729\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 0s 115ms/step - loss: 1.3561 - accuracy: 0.0686 - val_loss: 0.7302 - val_accuracy: 0.0729\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 0s 118ms/step - loss: 1.3561 - accuracy: 0.0686 - val_loss: 0.7307 - val_accuracy: 0.0729\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 0s 115ms/step - loss: 1.3561 - accuracy: 0.0686 - val_loss: 0.7309 - val_accuracy: 0.0729\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHzIIZ8Iu1Zd"
      },
      "source": [
        "#insert chris predict model function here "
      ],
      "execution_count": 774,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VxaBQ62UJTi"
      },
      "source": [
        "nlp = gensim_api.load(\"word2vec-google-news-300\")\n",
        "#this might take some time"
      ],
      "execution_count": 775,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWDmHRopY-yp"
      },
      "source": [
        "from gensim.test.utils import common_texts\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "model = Word2Vec(sentences=common_texts, size=100, window=5, min_count=1, workers=4) #vector_size\n",
        "model.save(\"word2vec.model\")"
      ],
      "execution_count": 776,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kXasPSTZdtu",
        "outputId": "4a22c624-233c-424d-d831-96fbe7870183",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = Word2Vec.load(\"word2vec.model\")\n",
        "model.train([[\"hello\", \"world\"]], total_examples=1, epochs=1)"
      ],
      "execution_count": 777,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 777
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNZyxURiaJoE"
      },
      "source": [
        "vector = model.wv['computer'] \n",
        "sims = model.wv.most_similar('computer', topn=10)\n",
        "word_vectors = model.wv\n",
        "word_vectors.save(\"word2vec.wordvectors\")"
      ],
      "execution_count": 778,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_TYXPoMcGxo",
        "outputId": "b6a1b3a3-7640-40b8-a73c-c167605253d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "sentences = [[\"cat\", \"say\", \"meow\"], [\"dog\", \"say\", \"woof\"]]\n",
        "\n",
        "model = Word2Vec(min_count=1)\n",
        "\n",
        "model.build_vocab(sentences)  # prepare the model vocabulary\n",
        "\n",
        "model.train(sentences, total_examples=model.corpus_count, epochs=model.epochs)  # train"
      ],
      "execution_count": 779,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 30)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 779
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uc4vot3DaIoH"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vtc7ExQUTGc",
        "outputId": "3becba6d-5cad-4694-b613-4dd6dcc409ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        }
      },
      "source": [
        "import gensim\n",
        "\n",
        "model = gensim.models.KeyedVectors.load_word2vec_format('wordvectors.kv', binary=False)\n",
        "# if you vector file is in binary format, change to binary=True\n",
        "sentence = [\"London\", \"is\", \"the\", \"capital\", \"of\", \"Great\", \"Britain\"]\n",
        "vectors = [model[w] for w in sentence]"
      ],
      "execution_count": 780,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-780-46f5b1ee096c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wordvectors.kv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# if you vector file is in binary format, change to binary=True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"London\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"is\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"the\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"capital\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"of\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Great\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Britain\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[1;32m   1436\u001b[0m         return _load_word2vec_format(\n\u001b[1;32m   1437\u001b[0m             \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1438\u001b[0;31m             limit=limit, datatype=datatype)\n\u001b[0m\u001b[1;32m   1439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_keras_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/utils_any2vec.py\u001b[0m in \u001b[0;36m_load_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loading projection weights from %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmart_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m         \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# throws for invalid file format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36msmart_open\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    496\u001b[0m     \u001b[0mignore_ext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mignore_extension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_extension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, ignore_ext, compression, transport_params)\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m     )\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36m_shortcut_open\u001b[0;34m(uri, mode, compression, buffering, encoding, errors, newline)\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0mopen_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'errors'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_builtin_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mopen_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'wordvectors.kv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfYxqL-GDkC1"
      },
      "source": [
        "azubi_df_mails_and_scored_combined.head(5)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrBQWhIM389K"
      },
      "source": [
        "this is an intentional error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWSkD1ch_T8a"
      },
      "source": [
        "# Bag of Words\n",
        "The more simple bow approach was also testes but didn't work. Thus, we exclude the coding here..\n",
        "\n",
        "Bag-of-words refers to what kind of information you can extract from a document (namely, unigram words). Vector space model refers to the data structure for each document (namely, a feature vector of term & term weight pairs). Both aspects complement each other. (Stackoverflow, 2021)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3U-2O6LU1-Sg"
      },
      "source": [
        "# Build Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZHxdFUhQEjs"
      },
      "source": [
        "## Fit learning rate\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEvAKhgRJ1XS"
      },
      "source": [
        "def fitLearningRate(training_padded, training_labels,validation_padded, validation_label, vocab_size, embedding_dim, max_length, num_epochs):\n",
        "  \n",
        "  model = tf.keras.Sequential([\n",
        "  #model design\n",
        "  #tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "  #tf.keras.layers.GlobalAveragePooling1D(), #fiddle #MaxPooling1D(pool_size=)\n",
        "  #tf.keras.layers.Dense(16, activation='relu'), #fiddle\n",
        "  #tf.keras.layers.Dense(5, activation='softmax')]) #5 scores, 5 outputs per scenario\n",
        "   \n",
        "  tf.keras.layers.Embedding(vocab_size+1, embedding_dim, input_length=max_length),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  #tf.keras.layers.Conv1D(32, 5, activation='sigmoid'),\n",
        "  #tf.keras.layers.MaxPooling1D(pool_size=4),\n",
        "  tf.keras.layers.LSTM(32),\n",
        "  tf.keras.layers.Dropout(0.3),\n",
        "  tf.keras.layers.Dense(16, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(7, activation='softmax')])\n",
        "  \n",
        "  #Fit the model\n",
        "  #Input: compiled Model, Train and Validation Data, Batch Size and trainingEpochs\n",
        "  #Return: history and model\n",
        "  optimizer = tf.keras.optimizers.RMSprop(lr=1e-6)\n",
        "  model.compile(optimizer = optimizer,\n",
        "                loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  lr_schedule = tf.keras.callbacks.LearningRateScheduler(\n",
        "    lambda epoch: 1e-6 * 10**(epoch / 20))\n",
        "  \n",
        "  #one hot encode\n",
        "  training_labels = np.array(training_labels)\n",
        "  validation_label = np.array(validation_label)\n",
        "  training_labels = np.concatenate((training_labels))\n",
        "  validation_label = np.concatenate((validation_label))\n",
        "  training_labels = to_categorical(training_labels, 7)\n",
        "  validation_label = to_categorical(validation_label, 7)\n",
        "\n",
        "  print(\"xtrain\")\n",
        "  print(training_padded.shape)\n",
        "  print(\"ytrain\")\n",
        "  print(training_labels.shape)\n",
        "  print(\"xval\")\n",
        "  print(validation_padded.shape)\n",
        "  print(\"yval\")\n",
        "  print(validation_label.shape)\n",
        "  \n",
        "\n",
        "  # fit network\n",
        "  history = model.fit(training_padded, training_labels, epochs=num_epochs, validation_data=(validation_padded, validation_label),callbacks=[lr_schedule], verbose=2)\n",
        "\n",
        "  # plot history\n",
        "  plt.semilogx(history.history[\"lr\"], history.history[\"loss\"])\n",
        "  plt.show()\n",
        "  #pyplot.legend()\n",
        "  #pyplot.show()\n",
        "  #history = compiledModel.fit(xTrain, yTrain,batch_size=512, epochs = trainingEpochs,callbacks=[lr_schedule])\n",
        "\n",
        "  return model, history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDQRA2vPQK1o"
      },
      "source": [
        "## First approach"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufvoThLsrFGi"
      },
      "source": [
        "### Startermodel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnRvEIU1s9xa"
      },
      "source": [
        "def startermodel(training_padded, training_labels,validation_padded, validation_label, vocab_size, embedding_dim, max_length, num_epochs): #weights=[embeddings_matrix], trainable=False\n",
        "\n",
        "  model = tf.keras.Sequential([\n",
        "    #model design\n",
        "    #tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    #tf.keras.layers.GlobalAveragePooling1D(), #fiddle #MaxPooling1D(pool_size=)\n",
        "    #tf.keras.layers.Dense(16, activation='relu'), #fiddle\n",
        "    #tf.keras.layers.Dense(5, activation='softmax')]) #5 scores, 5 outputs per scenario\n",
        "    \n",
        "    tf.keras.layers.Embedding(vocab_size+1, embedding_dim, input_length=max_length),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    #tf.keras.layers.Conv1D(32, 5, activation='sigmoid'),\n",
        "    #tf.keras.layers.MaxPooling1D(pool_size=4),\n",
        "    tf.keras.layers.LSTM(32),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(16, activation='sigmoid'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(7, activation='softmax')])\n",
        "    \n",
        "  model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "  model.summary()\n",
        "  \n",
        "  #one hot encode\n",
        "  training_labels = np.array(training_labels)\n",
        "  validation_label = np.array(validation_label)\n",
        "  training_labels = np.concatenate((training_labels))\n",
        "  validation_label = np.concatenate((validation_label))\n",
        "  training_labels = to_categorical(training_labels, 7)\n",
        "  validation_label = to_categorical(validation_label, 7)\n",
        "\n",
        "  print(\"xtrain\")\n",
        "  print(training_padded.shape)\n",
        "  print(\"ytrain\")\n",
        "  print(training_labels.shape)\n",
        "  print(\"xval\")\n",
        "  print(validation_padded.shape)\n",
        "  print(\"yval\")\n",
        "  print(validation_label.shape)\n",
        "  \n",
        "\n",
        "  # fit network\n",
        "  history = model.fit(training_padded, training_labels, epochs=num_epochs, validation_data=(validation_padded, validation_label), verbose=2)\n",
        "  \n",
        "  # plot history\n",
        "  pyplot.plot(history.history['loss'], label='train')\n",
        "  pyplot.plot(history.history['val_loss'], label='test')\n",
        "  pyplot.legend()\n",
        "  pyplot.show()\n",
        " \n",
        "          \n",
        "  return model, history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaU4Gsx7rApw"
      },
      "source": [
        "### Bidirectional"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBaAiHgm5Q5t"
      },
      "source": [
        "def startermodelBidirectional(training_padded, training_labels,validation_padded, validation_label, vocab_size, embedding_dim, max_length, num_epochs): #weights=[embeddings_matrix], trainable=False\n",
        "\n",
        "  model = tf.keras.Sequential([\n",
        "    #model design\n",
        "    #tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    #tf.keras.layers.GlobalAveragePooling1D(), #fiddle #MaxPooling1D(pool_size=)\n",
        "    #tf.keras.layers.Dense(16, activation='relu'), #fiddle\n",
        "    #tf.keras.layers.Dense(5, activation='softmax')]) #5 scores, 5 outputs per scenario\n",
        "    \n",
        "    tf.keras.layers.Embedding(vocab_size+1, embedding_dim, input_length=max_length),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    #tf.keras.layers.Conv1D(32, 5, activation='sigmoid'),\n",
        "    #tf.keras.layers.MaxPooling1D(pool_size=4),\n",
        "    tf.keras.layers.Bidirectional(LSTM(32)),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(16, activation='sigmoid'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(7, activation='softmax')])\n",
        "    \n",
        "  model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "  model.summary()\n",
        "  \n",
        "  #one hot encode\n",
        "  training_labels = np.array(training_labels)\n",
        "  validation_label = np.array(validation_label)\n",
        "  training_labels = np.concatenate((training_labels))\n",
        "  validation_label = np.concatenate((validation_label))\n",
        "  training_labels = to_categorical(training_labels, 7)\n",
        "  validation_label = to_categorical(validation_label, 7)\n",
        "\n",
        "  print(\"xtrain\")\n",
        "  print(training_padded.shape)\n",
        "  print(\"ytrain\")\n",
        "  print(training_labels.shape)\n",
        "  print(\"xval\")\n",
        "  print(validation_padded.shape)\n",
        "  print(\"yval\")\n",
        "  print(validation_label.shape)\n",
        "  \n",
        "\n",
        "  # fit network\n",
        "  history = model.fit(training_padded, training_labels, epochs=num_epochs, validation_data=(validation_padded, validation_label), verbose=2)\n",
        "\n",
        "  # plot history\n",
        "  pyplot.plot(history.history['loss'], label='train')\n",
        "  pyplot.plot(history.history['val_loss'], label='test')\n",
        "  pyplot.legend()\n",
        "  pyplot.show()\n",
        "          \n",
        "  return model, history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQzDyBkPQPU2"
      },
      "source": [
        "## Experimental approaches\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHDSzirMs8dC"
      },
      "source": [
        "## Bert Model Multilingual"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwcTbrw-uu8L"
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9-fOnbttANM"
      },
      "source": [
        "from transformers import pipeline\n",
        "from transformers import BertTokenizer, TFBertModel\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
        "model = TFBertModel.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "text = \"Replace me by any text you'd like.\"\n",
        "encoded_input = tokenizer(text, return_tensors='tf')\n",
        "output = model(encoded_input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScATUuBBvzwu"
      },
      "source": [
        "encoded_input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGC59WrNvE6N"
      },
      "source": [
        "pip install -q -U tensorflow-text\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00MgZvJZvIGZ"
      },
      "source": [
        "pip install -q tf-models-official\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veZT_-JjvCkp"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "from official.nlp import optimization  # to create AdamW optimizer\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NztAzQgOt1MW"
      },
      "source": [
        "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxXazU9Fzxt-"
      },
      "source": [
        "# install simpletransformers\n",
        "!pip install simpletransformers\n",
        "\n",
        "# check installed version\n",
        "!pip freeze | grep simpletransformers\n",
        "# simpletransformers==0.28.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycPlyMPl01nP"
      },
      "source": [
        "azubi_df_mails_and_scored_combined"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fABPYNx_0Db4"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "class_list = ['Impolite','Polite']\n",
        "\n",
        "#df1 = pd.read_csv('germeval2019GoldLabelsSubtask1_2.txt',sep='\\t', lineterminator='\\n',encoding='utf8',names=[\"tweet\", \"task1\", \"task2\"])\n",
        "#df2 = pd.read_csv('germeval2019.training_subtask1_2_korrigiert.txt',sep='\\t', lineterminator='\\n',encoding='utf8',names=[\"tweet\", \"task1\", \"task2\"])\n",
        "\n",
        "#df = pd.concat([df1,df2])\n",
        "#df['task2'] = df['task2'].str.replace('\\r', \"\")\n",
        "#df['pred_class'] = df.apply(lambda x:  class_list.index(x['task2']),axis=1)\n",
        "\n",
        "\n",
        "df =azubi_df_mails_and_scored_combined #df[['tweet','pred_class']]\n",
        "\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eR6oANfO19SM"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, test_df = train_test_split(df, test_size=0.10)\n",
        "\n",
        "print('train shape: ',train_df.shape)\n",
        "print('test shape: ',test_df.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jguhRrS70ATj"
      },
      "source": [
        "from simpletransformers.classification import ClassificationModel\n",
        "\n",
        "# define hyperparameter\n",
        "train_args ={\"reprocess_input_data\": True,\n",
        "             \"overwrite_output_dir\": True,\n",
        "             \"fp16\":False,\n",
        "             \"num_train_epochs\": 10}\n",
        "\n",
        "# Create a ClassificationModel\n",
        "model = ClassificationModel(\n",
        "    \"bert\", \"distilbert-base-german-cased\",\n",
        "    #num_labels=1,\n",
        "    args=train_args\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6MZFIY4N6OK"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XJ-B70W7Bro"
      },
      "source": [
        "xTrainArray, yTrainArray, xValArray, yValArray, xTestArray, yTestArray"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ga5PjPtT7jtF"
      },
      "source": [
        "type(yTrainArray)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Y2EvDEt65nx"
      },
      "source": [
        "# Creating pandas dataframe from numpy array\n",
        "train_data = pd.DataFrame({'Mails_Combined': xTrainArray, 'a4s_combined_i2b': yTrainArray[:,1]})\n",
        "val_data = pd.DataFrame({'Mails_Combined': xValArray, 'a4s_combined_i2b': yValArray[:,1]})\n",
        "test_data = pd.DataFrame({'Mails_Combined': xTestArray, 'a4s_combined_i2b': yTestArray[:,1]})\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J86qD4EA7Q1g"
      },
      "source": [
        "test_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8-R1F1U2LLu"
      },
      "source": [
        "# Train the model\n",
        "model.train_model(train_df=train_data, eval_df=val_data)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjLyvDN82yW2"
      },
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "\n",
        "\n",
        "def f1_multiclass(labels, preds):\n",
        "    return f1_score(labels, preds, average='micro')\n",
        "    \n",
        "result, model_outputs, wrong_predictions = model.eval_model(val_data, f1=f1_score, acc=accuracy_score)\n",
        "\n",
        "result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4ZiCcCpU76m"
      },
      "source": [
        "model_outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dWMZJmq3Ej_"
      },
      "source": [
        "class_list = ['Impolite','Polite']\n",
        "\n",
        "for i in range(len(test_data)):\n",
        "\n",
        "  test_tweet = test_data['Mails_Combined'][i]\n",
        "  predictions, raw_outputs = model.predict([test_tweet])\n",
        "\n",
        "  if predictions[0] != 1:\n",
        "    print(i)\n",
        "    print(raw_outputs)\n",
        "    print(class_list[predictions[0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CpREvBAF1cl"
      },
      "source": [
        "test_data['Mails_Combined'][83]\n",
        "test_data['Mails_Combined'][92]\n",
        "test_data['Mails_Combined'][129]\n",
        "test_data['Mails_Combined'][149]\n",
        "test_data['Mails_Combined'][174]\n",
        "test_data['Mails_Combined'][210]\n",
        "test_data['Mails_Combined'][264]\n",
        "test_data['Mails_Combined'][283]\n",
        "test_data['Mails_Combined'][303]\n",
        "test_data['Mails_Combined'][308]\n",
        "test_data['Mails_Combined'][329]\n",
        "test_data['Mails_Combined'][338]\n",
        "test_data['Mails_Combined'][342]\n",
        "test_data['Mails_Combined'][344]\n",
        "test_data['Mails_Combined'][357]\n",
        "test_data['Mails_Combined'][391]\n",
        "\n",
        "test_data['a4s_combined_i2b'][83]\n",
        "test_data['a4s_combined_i2b'][92]\n",
        "test_data['a4s_combined_i2b'][129]\n",
        "test_data['a4s_combined_i2b'][149]\n",
        "test_data['a4s_combined_i2b'][174]\n",
        "test_data['a4s_combined_i2b'][210]\n",
        "test_data['a4s_combined_i2b'][264]\n",
        "test_data['a4s_combined_i2b'][283]\n",
        "test_data['a4s_combined_i2b'][303]\n",
        "test_data['a4s_combined_i2b'][308]\n",
        "test_data['a4s_combined_i2b'][329]\n",
        "test_data['a4s_combined_i2b'][338]\n",
        "test_data['a4s_combined_i2b'][342]\n",
        "test_data['a4s_combined_i2b'][344]\n",
        "test_data['a4s_combined_i2b'][357]\n",
        "test_data['a4s_combined_i2b'][391]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jt2z5V3dNNB"
      },
      "source": [
        "test_data['a4s_combined_i2b'][264]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fN058AbudLy-"
      },
      "source": [
        "test_data['Mails_Combined'][264]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esKYDxDbFvOa"
      },
      "source": [
        "test_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oemQjjz2k9JE"
      },
      "source": [
        "### Transfer model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHeKBFmdH0Am"
      },
      "source": [
        "def transferModelSimple(training_padded, training_labels,validation_padded, validation_label, vocab_size, embedding_dim, max_length,\n",
        "                        num_epochs, hub_layer, shape, oneHotEncode, outputClasses): #weights=[embeddings_matrix], trainable=False\n",
        "\n",
        "  model = tf.keras.Sequential()\n",
        "  \n",
        "  model.add(hub_layer)\n",
        "  #model.add(Dense(16, activation='relu'))\n",
        "  #model.add(Dense(20, activation = \"relu\"))\n",
        "  model.add(tf.keras.layers.Reshape((shape, 1)))\n",
        "  model.add(Bidirectional(LSTM(256, return_sequences=True))) #recurrent_dropout=0.2\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Bidirectional(LSTM(32)))\n",
        "  model.add(Dropout(0.2))\n",
        "  #model.add(Dense(16, activation='relu')) #, kernel_regularizer='L2'\n",
        "  #model.add(Dropout(0.2))\n",
        "  model.add(Dense(training_labels.shape[1], activation='softmax'))\n",
        "\n",
        "  \n",
        "  metric = tf.keras.metrics.CategoricalAccuracy()\n",
        "  #metric = tf.keras.metrics.sparse_categorical_accuracy()\n",
        "  #metric = tf.keras.metrics.TopKCategoricalAccuracy(\n",
        "  #  k=3, name=\"top_k_categorical_accuracy\", dtype=None)\n",
        "\n",
        "  loss = tf.keras.losses.CategoricalCrossentropy(\n",
        "      from_logits=False,\n",
        "      label_smoothing=0,\n",
        "      reduction=\"auto\",\n",
        "      name=\"categorical_crossentropy\",\n",
        "  )\n",
        "\n",
        "\n",
        "  lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=1e-1,\n",
        "    decay_steps=20000,\n",
        "    decay_rate=0.99)\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=1e-2) \n",
        "  model.compile(loss='categorical_crossentropy',optimizer=optimizer ,metrics=metric)\n",
        "  model.summary()\n",
        "  model.save_weights('modelTrans.h5')\n",
        "  \n",
        "  if (oneHotEncode == True):\n",
        "    #one hot encode\n",
        "    training_labels = np.array(training_labels)\n",
        "    validation_label = np.array(validation_label)\n",
        "    training_labels = np.concatenate((training_labels))\n",
        "    validation_label = np.concatenate((validation_label))\n",
        "    training_labels = to_categorical(training_labels, 7)\n",
        "    validation_label = to_categorical(validation_label, 7)\n",
        "   \n",
        "\n",
        "  training_padded = np.array(training_padded)\n",
        "  validation_padded = np.array(validation_padded)\n",
        "  #print(\"xtrain\")\n",
        "  #print(training_padded.shape)\n",
        "  #print(\"ytrain\")\n",
        "  #print(training_labels.shape)\n",
        "  #print(\"xval\")\n",
        "  #print(validation_padded.shape)\n",
        "  #print(\"yval\")\n",
        "  #print(validation_label.shape)\n",
        "  \n",
        "  #training_padded = training_padded.reshape(training_padded.shape[0],training_padded.shape[1],1)\n",
        "  #validation_padded = validation_padded.reshape(validation_padded.shape[0],validation_padded.shape[1],1)\n",
        "  # fit network\n",
        "  history = model.fit(training_padded, training_labels, epochs=num_epochs,batch_size=128, validation_data=(validation_padded, validation_label), verbose=2)\n",
        "  returnmodel = model\n",
        "  model.load_weights('modelTrans.h5')\n",
        "  # plot history\n",
        "  pyplot.plot(history.history['loss'], label='train')\n",
        "  pyplot.plot(history.history['val_loss'], label='test')\n",
        "  pyplot.legend()\n",
        "  pyplot.show()\n",
        "\n",
        "  pyplot.plot(history.history['categorical_accuracy'], label='train')\n",
        "  pyplot.plot(history.history['val_categorical_accuracy'], label='test')\n",
        "  pyplot.legend()\n",
        "  pyplot.show()\n",
        "          \n",
        "  return returnmodel, history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K71vNy_lk_ka"
      },
      "source": [
        "### Bidirectional "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pbEIwCvI-yG"
      },
      "source": [
        "def startermodelBidirectionalExperimental(training_padded, training_labels,validation_padded, validation_label, vocab_size, embedding_dim, max_length, num_epochs): #weights=[embeddings_matrix], trainable=False\n",
        "\n",
        "  model = tf.keras.Sequential([\n",
        "    #model design\n",
        "    #tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    #tf.keras.layers.GlobalAveragePooling1D(), #fiddle #MaxPooling1D(pool_size=)\n",
        "    #tf.keras.layers.Dense(16, activation='relu'), #fiddle\n",
        "    #tf.keras.layers.Dense(5, activation='softmax')]) #5 scores, 5 outputs per scenario\n",
        "    \n",
        "    tf.keras.layers.Embedding(input_dim = vocab_size+1, output_dim = embedding_dim, input_length=max_length, mask_zero=True),\n",
        "    \n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    #tf.keras.layers.Conv1D(64, 7, activation='sigmoid'),\n",
        "    #tf.keras.layers.MaxPooling1D(pool_size=4),\n",
        "    #tf.keras.layers.Bidirectional(LSTM(64, return_sequences=True, input_shape=training_padded.shape)), #recurrent_dropout=0.2\n",
        "    #tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.LSTM(16),\n",
        "    #tf.keras.layers.Dense(16, activation='relu', kernel_regularizer='L2'), #kernel_regularizer='l2'\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(training_labels.shape[1], activation='softmax')])\n",
        "  \n",
        "  metric = tf.keras.metrics.CategoricalAccuracy()\n",
        "  lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=1e-2,\n",
        "    decay_steps=20000,\n",
        "    decay_rate=0.95)\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule) \n",
        "  model.compile(loss='categorical_crossentropy',optimizer=optimizer ,metrics=metric)\n",
        "  model.summary()\n",
        "  model.save_weights('model.h5')\n",
        "  \n",
        "\n",
        "  # fit network\n",
        "  history = model.fit(training_padded, training_labels, epochs=num_epochs,batch_size=32, validation_data=(validation_padded, validation_label), verbose=2)\n",
        "  returnmodel = model\n",
        "  model.load_weights('model.h5')\n",
        "  # plot history\n",
        "  showModelPerformance(history, \"loss\")\n",
        "  showModelPerformance(history, \"categorical_accuracy\")\n",
        "\n",
        "  #pyplot.plot(history.history['loss'], label='train')\n",
        "  #pyplot.plot(history.history['val_loss'], label='test')\n",
        "  #pyplot.legend()\n",
        "  #pyplot.show()\n",
        "\n",
        "  #pyplot.plot(history.history['categorical_accuracy'], label='train')\n",
        "  #pyplot.plot(history.history['val_categorical_accuracy'], label='test')\n",
        "  #pyplot.legend()\n",
        "  #pyplot.show()\n",
        "          \n",
        "  return returnmodel, history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkD1FcIslB3w"
      },
      "source": [
        "### Bidirectional Binary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JFQauRyNuud"
      },
      "source": [
        "def startermodelBidirectionalExperimentalBinary(training_padded, training_labels,validation_padded, validation_label, vocab_size, \n",
        "                                                embedding_dim, max_length, num_epochs): #weights=[embeddings_matrix], trainable=False\n",
        "\n",
        "  model = tf.keras.Sequential([\n",
        "   \n",
        "    tf.keras.layers.Embedding(input_dim = vocab_size+1, output_dim = embedding_dim, input_length=max_length, mask_zero=False), #eventuell mask_zero false \n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.LSTM(16),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    #tf.keras.layers.Dense(8, activation='relu'),\n",
        "    #tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')])\n",
        "  \n",
        "  metric = tf.keras.metrics.BinaryAccuracy()\n",
        "  lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=1e-2,\n",
        "    decay_steps=10000,\n",
        "    decay_rate=0.8)\n",
        "  \n",
        "  optimizerAdam = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "  optimizerSGD = tf.keras.optimizers.SGD(learning_rate=lr_schedule)\n",
        "\n",
        "  model.compile(loss='binary_crossentropy',optimizer=optimizerAdam ,metrics=metric)\n",
        "  model.summary()\n",
        "  model.save_weights('model.h5')\n",
        "  \n",
        "  #one hot encode\n",
        "  #training_labels = np.array(training_labels)\n",
        "  #validation_label = np.array(validation_label)\n",
        "  #training_labels = np.concatenate((training_labels))\n",
        "  #validation_label = np.concatenate((validation_label))\n",
        "  #training_labels = to_categorical(training_labels, 7)\n",
        "  #validation_label = to_categorical(validation_label, 7)\n",
        "\n",
        "  #print(\"xtrain\")\n",
        "  #print(training_padded.shape)\n",
        "  #print(\"ytrain\")\n",
        "  #print(training_labels.shape)\n",
        "  #print(\"xval\")\n",
        "  #print(validation_padded.shape)\n",
        "  #print(\"yval\")\n",
        "  #print(validation_label.shape)\n",
        "\n",
        "  #training_labels = np.asarray(training_labels).astype('float32').reshape((-1,1))\n",
        "  #validation_label = np.asarray(validation_label).astype('float32').reshape((-1,1))\n",
        "  class_weights = {0: 1.,\n",
        "                1: 0.1}\n",
        "\n",
        "  # fit network\n",
        "  history = model.fit(training_padded, training_labels, epochs=num_epochs,batch_size=32, validation_data=(validation_padded, validation_label), verbose=2)\n",
        "  returnmodel = model\n",
        "  model.load_weights('model.h5')\n",
        "  # plot history\n",
        "  pyplot.plot(history.history['loss'], label='train')\n",
        "  pyplot.plot(history.history['val_loss'], label='test')\n",
        "  pyplot.legend()\n",
        "  pyplot.show()\n",
        "\n",
        "  pyplot.plot(history.history['binary_accuracy'], label='train')\n",
        "  pyplot.plot(history.history['val_binary_accuracy'], label='test')\n",
        "  pyplot.legend()\n",
        "  pyplot.show()\n",
        "          \n",
        "  return returnmodel, history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVX3KSFClDpR"
      },
      "source": [
        "### Predict Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-qcn_d9tnPU"
      },
      "source": [
        "def predictModel(model, xTest, yTest):\n",
        "\n",
        "  predictions = model.predict(xTest)\n",
        "  print(predictions.size)\n",
        "  print(yTest.size)\n",
        "\n",
        "  class_labels = np.argmax(predictions, axis=1)\n",
        "  print(\"Class Labels:\\n\")\n",
        "  print(class_labels)\n",
        "  test_labels = np.argmax(yTest, axis=1)\n",
        "  print(\"Test Labels:\\n\")\n",
        "  print(test_labels)\n",
        "  #class_labels_reshaped = class_labels.reshape(yTest.shape[0],yTest.shape[1])\n",
        "  class_labels_diff = class_labels - test_labels\n",
        "  print(\"Class Labels Diff:\\n\")\n",
        "  print(class_labels_diff)\n",
        "  #label = [\"class1\", \"class2\", \"class3\", \"class4\", \"class5\", \"class6\"]\n",
        "  \n",
        "  print(len(xTest))\n",
        "  print(test_labels.shape)\n",
        "  print(class_labels.shape)\n",
        "\n",
        "  #plt.scatter(xTest, class_labels)\n",
        "  #plt.scatter(xTest, test_labels)\n",
        "\n",
        "  #plt.title('Test Set Predictions')\n",
        "  #plt.ylabel('class')\n",
        "\n",
        "  #plt.legend(loc=\"upper left\")\n",
        "  #plt.legend(['prediction', 'real test result'], loc='upper right')\n",
        "  #plt.show()\n",
        "\n",
        "  return predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVEDRS_19UIH"
      },
      "source": [
        "## Make and Run Models\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4gSiW19zvuD"
      },
      "source": [
        "#history.history.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5xcipzba5yC"
      },
      "source": [
        "xTrainArray, yTrainArray, xValArray, yValArray, xTestArray, yTestArray"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPWQjLMcIEVb"
      },
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "rus = RandomUnderSampler(random_state=0)\n",
        "rus.fit(xTrainArray, yTrainArray[:,0])\n",
        "X_resampled, y_resampled = rus.fit_sample(xTrainArray, yTrainArray[:,0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdzMHQdXIW-h"
      },
      "source": [
        "y_resampled"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFVBLLvOMkxP"
      },
      "source": [
        "model1234, history1234 = startermodelBidirectionalExperimentalBinary(X_resampled, y_resampled,xValArray, yValArray[:,0], vocab_size, embedding_dim, max_length, 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wSx_rZmm7zP"
      },
      "source": [
        "#model, history = startermodelBidirectionalExperimental(train_padded_single, yTrain_single,validation_padded_single, yVal_single, vocab_size, embedding_dim, max_length, 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sb6_sBc62uoF"
      },
      "source": [
        "hub_layer = hub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/nnlm-de-dim50-with-normalization/1\", output_shape=[50],\n",
        "                           input_shape=[], dtype=tf.string, trainable = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39csXGKV4KEK"
      },
      "source": [
        "#hub_layer = hub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/nnlm-de-dim128-with-normalization/1\", output_shape=[128],\n",
        "                           #input_shape=[], dtype=tf.string, trainable = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Btbjoz8Bthu7"
      },
      "source": [
        "#Adjust x and y parameters to correct names\n",
        "#model3, history3 = transferModelSimple(train_sum, yTrain_sum,validation_sum, yVal_sum, vocab_size, embedding_dim, max_length, 100, hub_layer, 50, False, 7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5oqSAK-LRYF"
      },
      "source": [
        "#model2, history2 = transferModelSimple(xTrain, yTrain_sum,xVal, yVal_sum, vocab_size, embedding_dim, max_length, 100, hub_layer, 50, False, 7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Fnel83DGt17"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CA6ZKOk5G5y"
      },
      "source": [
        "predictions1234 = predictModel(model1234,xTestArray, yTestArray)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R00YcxTIvoyG"
      },
      "source": [
        "# Primitive Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyJDEoqRvqqa"
      },
      "source": [
        "## Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acS1J9OttmR3"
      },
      "source": [
        "def NaiveBayesModel(X_train, y_train, X_test, y_test):\n",
        "  classifier = MultinomialNB()\n",
        "  nb = classifier.fit(X_train, y_train)\n",
        "  y_pred = classifier.predict(X_test)\n",
        "  return nb, y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcyM88Hdvr8n"
      },
      "source": [
        "## SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Bngdx1yvoHP"
      },
      "source": [
        "## Linear Support Vector Machine\n",
        "def svmModel(X_train, y_train, X_test, y_test):\n",
        "  sgd = Pipeline([('vect', CountVectorizer()),\n",
        "                ('tfidf', TfidfTransformer()),\n",
        "                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)),\n",
        "               ])\n",
        "  sgd.fit(X_train, y_train)\n",
        "\n",
        "  #%%time\n",
        "  \n",
        "  y_pred = sgd.predict(X_test)\n",
        "  my_tags = ['class 0', 'class 1']\n",
        "\n",
        "  print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "  print(classification_report(y_test, y_pred,target_names=my_tags))\n",
        "  return sgd, y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mmjl7BDVyYCG"
      },
      "source": [
        "##Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzQJqeUQyXlL"
      },
      "source": [
        "def lgModel(X_train, y_train, X_test, y_test):\n",
        "  logreg = Pipeline([('vect', CountVectorizer()),\n",
        "                ('tfidf', TfidfTransformer()),\n",
        "                ('clf', LogisticRegression(n_jobs=5, C=1e-1)), #C=1e5\n",
        "               ])\n",
        "  logreg.fit(X_train, y_train)\n",
        "\n",
        "  #%%time\n",
        "\n",
        "  y_pred = logreg.predict(X_test)\n",
        "  y_predProba = logreg.predict_proba(X_test)\n",
        "  my_tags = ['class 0', 'class 1']\n",
        "  print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "  print(classification_report(y_test, y_pred,target_names=my_tags))\n",
        "  return logreg, y_pred, y_predProba"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Vi-Wwg80pfn"
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01gAtqOY0orV"
      },
      "source": [
        "def randomtree_Model(n_estimators, X_train_sc, y_train, X_test_sc, y_test):\n",
        "    model = RandomForestClassifier(n_estimators = n_estimators, criterion  = 'entropy', random_state = 42)\n",
        "\n",
        "    history = model.fit(X_train_sc, y_train)\n",
        "\n",
        "    y_predict = model.predict(X_test_sc)\n",
        "\n",
        "    print(confusion_matrix(y_test,y_predict))\n",
        "    print(classification_report(y_test,y_predict))\n",
        "    print(accuracy_score(y_test, y_predict))\n",
        "    return model, history, y_predict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "we4aNM4I4bx_"
      },
      "source": [
        "# Execute Primitive Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9u3d-_bU0rT1"
      },
      "source": [
        "#Execute random forest model\n",
        "modelRandomForest,historyRandomForest, y_predictRandomForest = randomtree_Model(100, xTrainArray, yTrainArray[:,1], xValArray, yValArray[:,1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntgXVPRGyc4z"
      },
      "source": [
        "#Execute lgModel\n",
        "logreg, y_predLg, y_predProbaLg = lgModel(xTrainArray2, yTrainArray2[:,1], xValArray2, yValArray2[:,1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDjgLOWSvwwN"
      },
      "source": [
        "#Execute svmModel\n",
        "sgd, y_predSgd = svmModel(xTrainArray2, yTrainArray2[:,1], xValArray2, yValArray2[:,1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2T_IND4gtyaz"
      },
      "source": [
        "#Execute Naive Bayes Model\n",
        "nb, yPredictedNb = NaiveBayesModel(xTrainArray, yTrainArray[:,1], xValArray, yValArray[:,1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJ0_TuUZ78gb"
      },
      "source": [
        "# Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWfP0aCk89xp"
      },
      "source": [
        "# average the two word vectors\n",
        "def word_averaging(wv, words):\n",
        "    all_words, mean = set(), []\n",
        "    \n",
        "    for word in words:\n",
        "        if isinstance(word, np.ndarray):\n",
        "            mean.append(word)\n",
        "        elif word in wv.vocab:\n",
        "            mean.append(wv.syn0norm[wv.vocab[word].index])\n",
        "            all_words.add(wv.vocab[word].index)\n",
        "\n",
        "    if not mean:\n",
        "        logging.warning(\"cannot compute similarity with no input %s\", words)\n",
        "        # FIXME: remove these examples in pre-processing\n",
        "        return np.zeros(wv.vector_size,)\n",
        "\n",
        "    mean = gensim.matutils.unitvec(np.array(mean).mean(axis=0)).astype(np.float32)\n",
        "    return mean"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCXNg02_8_aS"
      },
      "source": [
        "def  word_averaging_list(wv, text_list):\n",
        "    return np.vstack([word_averaging(wv, post) for post in text_list ])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHeDjYs39BSS"
      },
      "source": [
        "# tokenize the text and apply the tokenization to \"post\" column, and apply word vector averaging to tokenized text\n",
        "def w2v_tokenize_text(text):\n",
        "    tokens = []\n",
        "    for sent in nltk.sent_tokenize(text, language='english'):\n",
        "        for word in nltk.word_tokenize(sent, language='english'):\n",
        "            if len(word) < 2:\n",
        "                continue\n",
        "            tokens.append(word)\n",
        "    return tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQ4wfsCu8vhN"
      },
      "source": [
        "def word2vecTokenizer(sentences):\n",
        "\n",
        "  wv = KeyedVectors.load_word2vec_format(\"GoogleNews-vectors-negative300.bin.gz\", binary=True) #gensim.models.\n",
        "  wv.init_sims(replace=True)\n",
        "\n",
        "  tokenized = sentences.apply(lambda r: w2v_tokenize_text(r['post']), axis=1).values\n",
        "\n",
        "  return tokenized"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mC-eUfCzBUBd"
      },
      "source": [
        "def word2vecTokenizer2(sentences, glove_vectors):\n",
        "\n",
        "  wv = glove_vectors\n",
        "  wv.init_sims(replace=True)\n",
        "\n",
        "  tokenized = sentences.apply(lambda r: w2v_tokenize_text(r['post']), axis=1).values\n",
        "\n",
        "  return tokenized"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzdWYN9489bB"
      },
      "source": [
        "#import gensim.downloader\n",
        "#print(list(gensim.downloader.info()['models'].keys()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYtF_PbVAgN7"
      },
      "source": [
        "#glove_vectors = gensim.downloader.load('glove-twitter-25')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}